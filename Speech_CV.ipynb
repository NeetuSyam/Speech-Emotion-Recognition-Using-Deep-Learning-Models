{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  <center> Speech Emotion Recognition <center>","metadata":{"id":"20F_SHnn4w3D"}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{"id":"pCI83-K84w3F"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nimport sys\n\n# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\nimport librosa\nimport librosa.display\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\n# to play the audio files\nfrom IPython.display import Audio\n\nimport keras\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\nfrom keras.utils import np_utils, to_categorical\nfrom keras.callbacks import ModelCheckpoint\n\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","id":"cy-K6Lvx4w3G","execution":{"iopub.status.busy":"2023-05-06T23:21:21.344290Z","iopub.execute_input":"2023-05-06T23:21:21.344712Z","iopub.status.idle":"2023-05-06T23:21:31.167734Z","shell.execute_reply.started":"2023-05-06T23:21:21.344676Z","shell.execute_reply":"2023-05-06T23:21:31.166406Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{"id":"mOaqd3Yv4w3H"}},{"cell_type":"code","source":"# Paths for data.\ndataset_path = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"","metadata":{"id":"n-1dSbi74w3H","execution":{"iopub.status.busy":"2023-05-06T23:21:31.170383Z","iopub.execute_input":"2023-05-06T23:21:31.171238Z","iopub.status.idle":"2023-05-06T23:21:31.176397Z","shell.execute_reply.started":"2023-05-06T23:21:31.171191Z","shell.execute_reply":"2023-05-06T23:21:31.175286Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Feature Extraction","metadata":{"id":"4aY7K7lM4w3H"}},{"cell_type":"code","source":"# Adding 3 types of data augmentation techniques\ndef noise(data):\n    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n    data = data + noise_amp*np.random.normal(size=data.shape[0])\n    return data\n\ndef stretch(audio_data):\n    return librosa.effects.time_stretch(audio_data, rate=0.8)\n\ndef shift(data):\n    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n    return np.roll(data, shift_range)","metadata":{"id":"-hRWYgNj4w3H","execution":{"iopub.status.busy":"2023-05-06T23:21:31.178267Z","iopub.execute_input":"2023-05-06T23:21:31.179150Z","iopub.status.idle":"2023-05-06T23:21:31.190456Z","shell.execute_reply.started":"2023-05-06T23:21:31.179087Z","shell.execute_reply":"2023-05-06T23:21:31.189233Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Function to Load data\ndef load_data(file_path):\n    audio, sampling_rate = librosa.load(file_path, duration=2.5, offset=0.6)\n    return audio","metadata":{"id":"dF06XHd-4w3H","execution":{"iopub.status.busy":"2023-05-06T23:21:31.193384Z","iopub.execute_input":"2023-05-06T23:21:31.193840Z","iopub.status.idle":"2023-05-06T23:21:31.206638Z","shell.execute_reply.started":"2023-05-06T23:21:31.193801Z","shell.execute_reply":"2023-05-06T23:21:31.205537Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Function to preprocess the data\ndef input_label_define(dataset_path):\n    y=[]\n    X=[]\n    gender=[]\n    actors = []\n    for folder in os.listdir(dataset_path):\n        for file in os.listdir(os.path.join(dataset_path, folder)):\n            if file.endswith('.wav'): \n                emotion = file.split('-')[2]\n                if int(emotion) == 1:\n                    label = 'Neutral'\n                elif int(emotion) == 2:\n                    label = 'Calm'\n                elif int(emotion) == 3:\n                    label = 'Happy'\n                elif int(emotion) == 4:\n                    label = 'Sad'\n                elif int(emotion) == 5:\n                    label = 'Angry'\n                elif int(emotion) == 6:\n                    label = 'Fearful'\n                elif int(emotion) == 7:\n                    label = 'Disgust'\n                elif int(emotion) == 8:\n                    label = 'Surprised'\n                else:\n                    label = 'UNK'\n                actor = int(file.split('-')[-1].split('.')[0])\n                         \n                file_path = os.path.join(dataset_path, folder, file)\n                audio_array=load_data(file_path)\n                \n                # gender\n                gender_value=file_path.split(\"-\")[-1].split(\".\")[0]\n                if (int(gender_value)%2)==0:\n                    gender_feature=0\n                else:\n                    gender_feature=1\n                \n                X.append(load_data(file_path))\n                y.append(label)\n                gender.append(gender_feature)\n                actors.append(actor)\n                \n                # data with noise\n                X.append(noise(audio_array))\n                y.append(label)\n                gender.append(gender_feature)\n                actors.append(actor)\n                \n                # Data with shift\n                X.append(shift(audio_array))\n                y.append(label)\n                gender.append(gender_feature)\n                actors.append(actor)\n                \n                # data with stretching and pitching\n                X.append(stretch(audio_array))\n                y.append(label)\n                gender.append(gender_feature)\n                actors.append(actor)\n            \n    return X,y,gender, actors","metadata":{"id":"PWQoRRcp4w3I","execution":{"iopub.status.busy":"2023-05-06T23:21:31.208514Z","iopub.execute_input":"2023-05-06T23:21:31.208983Z","iopub.status.idle":"2023-05-06T23:21:31.224625Z","shell.execute_reply.started":"2023-05-06T23:21:31.208942Z","shell.execute_reply":"2023-05-06T23:21:31.223277Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_r_aug, y_r_aug, gender, actors= input_label_define(dataset_path)","metadata":{"id":"i1phhb4Q4w3I","execution":{"iopub.status.busy":"2023-05-06T23:21:54.166178Z","iopub.execute_input":"2023-05-06T23:21:54.166555Z","iopub.status.idle":"2023-05-06T23:23:45.819218Z","shell.execute_reply.started":"2023-05-06T23:21:54.166525Z","shell.execute_reply":"2023-05-06T23:23:45.818305Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"np.array(X_r_aug).shape,np.array(y_r_aug).shape,np.array(y_r_aug).shape","metadata":{"id":"VOPokRhq4w3J","outputId":"42c3cfb5-9dab-46eb-efbc-d1f581098200","execution":{"iopub.status.busy":"2023-05-06T21:15:12.097543Z","iopub.execute_input":"2023-05-06T21:15:12.097901Z","iopub.status.idle":"2023-05-06T21:15:12.107580Z","shell.execute_reply.started":"2023-05-06T21:15:12.097860Z","shell.execute_reply":"2023-05-06T21:15:12.106586Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"((5760,), (5760,), (5760,))"},"metadata":{}}]},{"cell_type":"code","source":"# Saving the raw input data\n# import pickle\n\n# open a file in binary write mode\n# with open('RAVDESS_raw_aug.pkl', 'wb') as f:\n    # write the array to the file using pickle.dump()\n#     pickle.dump(np.array(X_r_aug), f)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:34:25.081538Z","iopub.execute_input":"2023-05-05T16:34:25.082431Z","iopub.status.idle":"2023-05-05T16:34:32.556903Z","shell.execute_reply.started":"2023-05-05T16:34:25.082388Z","shell.execute_reply":"2023-05-05T16:34:32.555375Z"},"id":"eZJZUsx24w3J","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extract Accoustic features","metadata":{"id":"FR22oao94w3J"}},{"cell_type":"code","source":"def acoustic_features(data):\n    # ZCR\n    result = np.array([])\n    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n    result=np.hstack((result, zcr)) # stacking horizontally\n\n    # Chroma_stft\n    stft = np.abs(librosa.stft(data))\n    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, chroma_stft)) # stacking horizontally\n\n    # MFCC\n    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, mfcc)) # stacking horizontally\n\n    # Root Mean Square Value\n    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n    result = np.hstack((result, rms)) # stacking horizontally\n\n    # MelSpectogram\n    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, mel)) # stacking horizontally\n    \n    return result","metadata":{"id":"w7gkwceL4w3K","execution":{"iopub.status.busy":"2023-05-06T21:15:21.089783Z","iopub.execute_input":"2023-05-06T21:15:21.090671Z","iopub.status.idle":"2023-05-06T21:15:21.098376Z","shell.execute_reply.started":"2023-05-06T21:15:21.090633Z","shell.execute_reply":"2023-05-06T21:15:21.097319Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"sampling_rate=22050","metadata":{"id":"oVDQK9c64w3K","execution":{"iopub.status.busy":"2023-05-06T21:15:23.980816Z","iopub.execute_input":"2023-05-06T21:15:23.981217Z","iopub.status.idle":"2023-05-06T21:15:23.985517Z","shell.execute_reply.started":"2023-05-06T21:15:23.981189Z","shell.execute_reply":"2023-05-06T21:15:23.984511Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_ac = []\nfor i in X_r_aug:\n    X_ac.append(acoustic_features(i))","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:51:45.542236Z","iopub.execute_input":"2023-05-06T19:51:45.542868Z","iopub.status.idle":"2023-05-06T19:59:58.091833Z","shell.execute_reply.started":"2023-05-06T19:51:45.542835Z","shell.execute_reply":"2023-05-06T19:59:58.090215Z"},"id":"5GOnWDH44w3K","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_ac=y_r_aug\nnp.array(X_ac).shape,np.array(y_ac).shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:02:02.711355Z","iopub.execute_input":"2023-05-06T20:02:02.711767Z","iopub.status.idle":"2023-05-06T20:02:02.725804Z","shell.execute_reply.started":"2023-05-06T20:02:02.711733Z","shell.execute_reply":"2023-05-06T20:02:02.724891Z"},"id":"6Up06S9Y4w3K","outputId":"6a517a4e-7aee-48ce-f607-0881c9388474","trusted":true},"execution_count":null,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"((5760, 162), (5760,))"},"metadata":{}}]},{"cell_type":"code","source":"# Accoustic features saved\n# np.save('RAVDESS_Aug_Acoustic.npy',np.array(X_ac))\n# np.save('RAVDESS_Aug_Acoustic_emotion.npy',np.array(y_ac))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:32:12.745035Z","iopub.execute_input":"2023-05-05T16:32:12.745560Z","iopub.status.idle":"2023-05-05T16:32:12.772013Z","shell.execute_reply.started":"2023-05-05T16:32:12.745515Z","shell.execute_reply":"2023-05-05T16:32:12.769925Z"},"id":"8Pp0hkvP4w3K","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extract Statistical Features","metadata":{"id":"Rwn0TaHK4w3K"}},{"cell_type":"code","source":"import os, glob\nimport librosa\nimport numpy as np\nimport scipy\n\n# Function to extract features from each audio file\ndef statistical_features(audio):\n    mean = np.mean(audio)\n    variance = np.var(audio)\n    skewness = scipy.stats.skew(audio)\n    kurtosis = scipy.stats.kurtosis(audio)\n    audio_rms = librosa.feature.rms(y=audio)\n    audio_rms_mean = audio_rms.mean()\n    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sampling_rate)[0]\n    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sampling_rate)[0]\n    mfccs = librosa.feature.mfcc(y=audio, sr=sampling_rate, n_mfcc=13)\n    mfcc = mfccs.mean()\n    return [mean, variance, skewness, kurtosis, audio_rms_mean, spectral_centroids.mean(), spectral_bandwidth.mean(), mfcc]\n  ","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:59:58.129474Z","iopub.execute_input":"2023-05-06T19:59:58.130700Z","iopub.status.idle":"2023-05-06T19:59:58.145144Z","shell.execute_reply.started":"2023-05-06T19:59:58.130640Z","shell.execute_reply":"2023-05-06T19:59:58.143530Z"},"id":"aSNpu78x4w3K","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_stat = []\nfor i in X_r_aug:\n    X_stat.append(statistical_features(i))\nnp.array(X_stat).shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:02:48.410645Z","iopub.execute_input":"2023-05-06T20:02:48.411026Z","iopub.status.idle":"2023-05-06T20:08:46.226820Z","shell.execute_reply.started":"2023-05-06T20:02:48.410999Z","shell.execute_reply":"2023-05-06T20:08:46.225338Z"},"id":"IJceAAy94w3L","outputId":"0a04fc13-61be-4df5-f4aa-256d35c920d2","trusted":true},"execution_count":null,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(5760, 8)"},"metadata":{}}]},{"cell_type":"code","source":"# Saving statistical features\n# np.save('RAVDESS_Aug_Stat.npy',np.array(X_stat))","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:08:46.229737Z","iopub.execute_input":"2023-05-06T20:08:46.230683Z","iopub.status.idle":"2023-05-06T20:08:46.238652Z","shell.execute_reply.started":"2023-05-06T20:08:46.230626Z","shell.execute_reply":"2023-05-06T20:08:46.237017Z"},"id":"yOS7Wchv4w3L","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_stat = np.load('/kaggle/input/ravdess-revathi-npy/RAVDESS_Aug_Stat.npy')\nX_ac = np.load('/kaggle/input/ravdess-revathi-npy/RAVDESS_Aug_Acoustic.npy')\ny_ac = np.load('/kaggle/input/ravdess-revathi-npy/RAVDESS_Augmented_emotion.npy')","metadata":{"execution":{"iopub.status.busy":"2023-05-06T23:23:45.821472Z","iopub.execute_input":"2023-05-06T23:23:45.822801Z","iopub.status.idle":"2023-05-06T23:23:45.973050Z","shell.execute_reply.started":"2023-05-06T23:23:45.822749Z","shell.execute_reply":"2023-05-06T23:23:45.972083Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"Features = pd.DataFrame(X_ac)\nFeatures['labels'] = y_ac\nFeatures.to_csv('features.csv', index=False)\nFeatures.head()","metadata":{"id":"P3D_3jdS4w3L","outputId":"678caac9-0fe0-4033-e06e-21c653db15cd","execution":{"iopub.status.busy":"2023-05-06T23:23:45.974485Z","iopub.execute_input":"2023-05-06T23:23:45.975151Z","iopub.status.idle":"2023-05-06T23:23:47.537457Z","shell.execute_reply.started":"2023-05-06T23:23:45.975105Z","shell.execute_reply":"2023-05-06T23:23:47.536410Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"          0         1         2         3         4         5         6  \\\n0  0.237382  0.682273  0.670519  0.614793  0.579039  0.566803  0.637206   \n1  0.331642  0.727662  0.734769  0.731634  0.710158  0.717446  0.743283   \n2  0.330164  0.730809  0.734809  0.727598  0.707369  0.717330  0.745340   \n3  0.329427  0.728282  0.734317  0.737076  0.720081  0.723116  0.740559   \n4  0.256113  0.621621  0.580278  0.598515  0.628296  0.598015  0.597272   \n\n          7         8         9  ...       153       154       155       156  \\\n0  0.667451  0.663883  0.669903  ...  0.000234  0.000235  0.000138  0.000128   \n1  0.713234  0.700561  0.683346  ...  0.001221  0.001236  0.001138  0.001159   \n2  0.724385  0.699645  0.686211  ...  0.001076  0.001074  0.000989  0.001015   \n3  0.714165  0.689678  0.682365  ...  0.001137  0.001108  0.001044  0.001099   \n4  0.650352  0.698636  0.681863  ...  0.000018  0.000016  0.000013  0.000012   \n\n        157       158       159       160           161     labels  \n0  0.000299  0.000360  0.000275  0.000173  2.896729e-05  Surprised  \n1  0.001292  0.001365  0.001208  0.001139  1.052731e-03  Surprised  \n2  0.001213  0.001241  0.001193  0.001121  8.812787e-04  Surprised  \n3  0.001215  0.001272  0.001126  0.001112  9.334161e-04  Surprised  \n4  0.000007  0.000008  0.000008  0.000005  5.802853e-07    Neutral  \n\n[5 rows x 163 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>153</th>\n      <th>154</th>\n      <th>155</th>\n      <th>156</th>\n      <th>157</th>\n      <th>158</th>\n      <th>159</th>\n      <th>160</th>\n      <th>161</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.237382</td>\n      <td>0.682273</td>\n      <td>0.670519</td>\n      <td>0.614793</td>\n      <td>0.579039</td>\n      <td>0.566803</td>\n      <td>0.637206</td>\n      <td>0.667451</td>\n      <td>0.663883</td>\n      <td>0.669903</td>\n      <td>...</td>\n      <td>0.000234</td>\n      <td>0.000235</td>\n      <td>0.000138</td>\n      <td>0.000128</td>\n      <td>0.000299</td>\n      <td>0.000360</td>\n      <td>0.000275</td>\n      <td>0.000173</td>\n      <td>2.896729e-05</td>\n      <td>Surprised</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.331642</td>\n      <td>0.727662</td>\n      <td>0.734769</td>\n      <td>0.731634</td>\n      <td>0.710158</td>\n      <td>0.717446</td>\n      <td>0.743283</td>\n      <td>0.713234</td>\n      <td>0.700561</td>\n      <td>0.683346</td>\n      <td>...</td>\n      <td>0.001221</td>\n      <td>0.001236</td>\n      <td>0.001138</td>\n      <td>0.001159</td>\n      <td>0.001292</td>\n      <td>0.001365</td>\n      <td>0.001208</td>\n      <td>0.001139</td>\n      <td>1.052731e-03</td>\n      <td>Surprised</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.330164</td>\n      <td>0.730809</td>\n      <td>0.734809</td>\n      <td>0.727598</td>\n      <td>0.707369</td>\n      <td>0.717330</td>\n      <td>0.745340</td>\n      <td>0.724385</td>\n      <td>0.699645</td>\n      <td>0.686211</td>\n      <td>...</td>\n      <td>0.001076</td>\n      <td>0.001074</td>\n      <td>0.000989</td>\n      <td>0.001015</td>\n      <td>0.001213</td>\n      <td>0.001241</td>\n      <td>0.001193</td>\n      <td>0.001121</td>\n      <td>8.812787e-04</td>\n      <td>Surprised</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.329427</td>\n      <td>0.728282</td>\n      <td>0.734317</td>\n      <td>0.737076</td>\n      <td>0.720081</td>\n      <td>0.723116</td>\n      <td>0.740559</td>\n      <td>0.714165</td>\n      <td>0.689678</td>\n      <td>0.682365</td>\n      <td>...</td>\n      <td>0.001137</td>\n      <td>0.001108</td>\n      <td>0.001044</td>\n      <td>0.001099</td>\n      <td>0.001215</td>\n      <td>0.001272</td>\n      <td>0.001126</td>\n      <td>0.001112</td>\n      <td>9.334161e-04</td>\n      <td>Surprised</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.256113</td>\n      <td>0.621621</td>\n      <td>0.580278</td>\n      <td>0.598515</td>\n      <td>0.628296</td>\n      <td>0.598015</td>\n      <td>0.597272</td>\n      <td>0.650352</td>\n      <td>0.698636</td>\n      <td>0.681863</td>\n      <td>...</td>\n      <td>0.000018</td>\n      <td>0.000016</td>\n      <td>0.000013</td>\n      <td>0.000012</td>\n      <td>0.000007</td>\n      <td>0.000008</td>\n      <td>0.000008</td>\n      <td>0.000005</td>\n      <td>5.802853e-07</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 163 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"Features.shape","metadata":{"id":"dVKSc88m4w3L","outputId":"75404c91-1094-40b4-85de-e06b7b538d97","execution":{"iopub.status.busy":"2023-05-06T23:23:47.539649Z","iopub.execute_input":"2023-05-06T23:23:47.541100Z","iopub.status.idle":"2023-05-06T23:23:47.549833Z","shell.execute_reply.started":"2023-05-06T23:23:47.541054Z","shell.execute_reply":"2023-05-06T23:23:47.548888Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(5760, 163)"},"metadata":{}}]},{"cell_type":"code","source":"# Combining both statistic and deep features and gender to create a common dataframe\nstat_col_index=len(Features.columns)\nstat_features=8\nX_stat_df = pd.DataFrame(X_stat,columns=list(range(stat_col_index,stat_col_index+stat_features)))\n\ngender_col_index=len(Features.columns)+stat_features\nX_gender_df=pd.DataFrame(gender,columns=list(range(gender_col_index,gender_col_index+1)))\n# stacking horizontally for getting all combinations\nX_ac_stat_nogen = pd.concat([Features, X_stat_df], axis=1)\n\nX_ac_stat = pd.concat([Features, X_stat_df,X_gender_df], axis=1)","metadata":{"id":"-3EvSzNx4w3L","execution":{"iopub.status.busy":"2023-05-06T23:23:47.551104Z","iopub.execute_input":"2023-05-06T23:23:47.551411Z","iopub.status.idle":"2023-05-06T23:23:47.571657Z","shell.execute_reply.started":"2023-05-06T23:23:47.551385Z","shell.execute_reply":"2023-05-06T23:23:47.570616Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"np.array(X_ac_stat).shape","metadata":{"id":"F71qTYOx4w3L","outputId":"d4bb7292-bc99-4e54-99f7-58135b3b54ba","execution":{"iopub.status.busy":"2023-05-06T23:23:47.573131Z","iopub.execute_input":"2023-05-06T23:23:47.573574Z","iopub.status.idle":"2023-05-06T23:23:47.669159Z","shell.execute_reply.started":"2023-05-06T23:23:47.573532Z","shell.execute_reply":"2023-05-06T23:23:47.668053Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(5760, 172)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{"id":"whKVP_So4w3M"}},{"cell_type":"code","source":"X = X_ac_stat.drop('labels',axis=1).values\nY = X_ac_stat['labels'].values","metadata":{"id":"K3UVQAkE4w3M","execution":{"iopub.status.busy":"2023-05-06T23:23:47.670597Z","iopub.execute_input":"2023-05-06T23:23:47.671462Z","iopub.status.idle":"2023-05-06T23:23:47.685436Z","shell.execute_reply.started":"2023-05-06T23:23:47.671423Z","shell.execute_reply":"2023-05-06T23:23:47.684339Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# As this is a multiclass classification problem onehotencoding our Y.\nencoder = OneHotEncoder()\nY = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()","metadata":{"id":"Wn5mC1eu4w3M","execution":{"iopub.status.busy":"2023-05-06T23:23:47.687370Z","iopub.execute_input":"2023-05-06T23:23:47.687826Z","iopub.status.idle":"2023-05-06T23:23:47.701613Z","shell.execute_reply.started":"2023-05-06T23:23:47.687781Z","shell.execute_reply":"2023-05-06T23:23:47.700173Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# splitting data\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,random_state=0, shuffle=True,stratify=Y)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"id":"Fue7vDMQ4w3M","outputId":"8c0d8c03-2ae8-452a-f1fd-25cfe5a28a57","execution":{"iopub.status.busy":"2023-05-06T23:23:47.702818Z","iopub.execute_input":"2023-05-06T23:23:47.703251Z","iopub.status.idle":"2023-05-06T23:23:47.782264Z","shell.execute_reply.started":"2023-05-06T23:23:47.703212Z","shell.execute_reply":"2023-05-06T23:23:47.780972Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"((4608, 171), (4608, 8), (1152, 171), (1152, 8))"},"metadata":{}}]},{"cell_type":"code","source":"# Normalizing our data with sklearn's Standard scaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"id":"_bzONQbw4w3M","outputId":"6dd33bd3-9221-4c53-ec61-757e8e616db0","execution":{"iopub.status.busy":"2023-05-06T23:23:47.786969Z","iopub.execute_input":"2023-05-06T23:23:47.787382Z","iopub.status.idle":"2023-05-06T23:23:47.811590Z","shell.execute_reply.started":"2023-05-06T23:23:47.787346Z","shell.execute_reply":"2023-05-06T23:23:47.810397Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"((4608, 171), (4608, 8), (1152, 171), (1152, 8))"},"metadata":{}}]},{"cell_type":"code","source":"# making our data compatible to model.\nx_train = np.expand_dims(x_train, axis=2)\nx_test = np.expand_dims(x_test, axis=2)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"id":"hdhJMLJx4w3M","outputId":"62cc243b-7feb-4d23-8638-d81665526284","execution":{"iopub.status.busy":"2023-05-06T23:23:47.813315Z","iopub.execute_input":"2023-05-06T23:23:47.814053Z","iopub.status.idle":"2023-05-06T23:23:47.823418Z","shell.execute_reply.started":"2023-05-06T23:23:47.813961Z","shell.execute_reply":"2023-05-06T23:23:47.821887Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"((4608, 171, 1), (4608, 8), (1152, 171, 1), (1152, 8))"},"metadata":{}}]},{"cell_type":"code","source":"# Acoustic feature segregation for deep feature extraction\nx_train_ac = x_train[:, :162]\nx_test_ac=x_test[:, :162]\n\nx_train_stat = x_train[:, 162:170]\nx_test_stat=x_test[:, 162:170]\n\nx_train_gen=x_train[:,-1]\nx_test_gen=x_test[:,-1]","metadata":{"id":"JHLnZJfA4w3M","execution":{"iopub.status.busy":"2023-05-06T23:23:47.825144Z","iopub.execute_input":"2023-05-06T23:23:47.826137Z","iopub.status.idle":"2023-05-06T23:23:47.833415Z","shell.execute_reply.started":"2023-05-06T23:23:47.826082Z","shell.execute_reply":"2023-05-06T23:23:47.831986Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"x_train_ac.shape,x_train_stat.shape,x_train_gen.shape","metadata":{"id":"ajUEkyLA4w3N","outputId":"76030a89-7615-402a-bf7f-247029829eea","execution":{"iopub.status.busy":"2023-05-06T23:23:47.834599Z","iopub.execute_input":"2023-05-06T23:23:47.834904Z","iopub.status.idle":"2023-05-06T23:23:47.846707Z","shell.execute_reply.started":"2023-05-06T23:23:47.834877Z","shell.execute_reply":"2023-05-06T23:23:47.845377Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"((4608, 162, 1), (4608, 8, 1), (4608, 1))"},"metadata":{}}]},{"cell_type":"code","source":"x_train_stat.shape,x_test_stat.shape,x_test_gen.shape","metadata":{"id":"g6_-FZBk4w3N","outputId":"bfdf521b-45a7-4832-b14a-6e3185c37578","execution":{"iopub.status.busy":"2023-05-06T23:23:47.847974Z","iopub.execute_input":"2023-05-06T23:23:47.848344Z","iopub.status.idle":"2023-05-06T23:23:47.859491Z","shell.execute_reply.started":"2023-05-06T23:23:47.848313Z","shell.execute_reply":"2023-05-06T23:23:47.858407Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"((4608, 8, 1), (1152, 8, 1), (1152, 1))"},"metadata":{}}]},{"cell_type":"code","source":"x_train_gen.shape,x_test_gen.shape","metadata":{"id":"k1Cz3Ntm4w3N","outputId":"1cf2bbb4-ad81-4126-c340-dfc969c19c5e","execution":{"iopub.status.busy":"2023-05-06T23:23:47.860482Z","iopub.execute_input":"2023-05-06T23:23:47.860801Z","iopub.status.idle":"2023-05-06T23:23:47.869294Z","shell.execute_reply.started":"2023-05-06T23:23:47.860774Z","shell.execute_reply":"2023-05-06T23:23:47.868436Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"((4608, 1), (1152, 1))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Modelling","metadata":{"id":"pjnkiORu4w3N"}},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train_ac.shape[1], 1)))\nmodel.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=32, activation='relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(units=8, activation='softmax'))\nmodel.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n\nmodel.summary()","metadata":{"id":"psh3vC_c4w3N","outputId":"21c68ca9-7a74-4d9d-f3b7-7ed5778356a3","execution":{"iopub.status.busy":"2023-05-06T23:23:47.870172Z","iopub.execute_input":"2023-05-06T23:23:47.870487Z","iopub.status.idle":"2023-05-06T23:23:48.164193Z","shell.execute_reply.started":"2023-05-06T23:23:47.870461Z","shell.execute_reply":"2023-05-06T23:23:48.163072Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv1d (Conv1D)             (None, 162, 256)          1536      \n                                                                 \n max_pooling1d (MaxPooling1D  (None, 81, 256)          0         \n )                                                               \n                                                                 \n flatten (Flatten)           (None, 20736)             0         \n                                                                 \n dense (Dense)               (None, 32)                663584    \n                                                                 \n dropout (Dropout)           (None, 32)                0         \n                                                                 \n dense_1 (Dense)             (None, 8)                 264       \n                                                                 \n=================================================================\nTotal params: 665,384\nTrainable params: 665,384\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.input","metadata":{"id":"iiY5Pg3Y4w3N","outputId":"95201d6d-8fa9-44e2-e919-9864dd3daed2","execution":{"iopub.status.busy":"2023-05-06T23:23:48.166231Z","iopub.execute_input":"2023-05-06T23:23:48.166681Z","iopub.status.idle":"2023-05-06T23:23:48.174105Z","shell.execute_reply.started":"2023-05-06T23:23:48.166638Z","shell.execute_reply":"2023-05-06T23:23:48.172941Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<KerasTensor: shape=(None, 162, 1) dtype=float32 (created by layer 'conv1d_input')>"},"metadata":{}}]},{"cell_type":"code","source":"x_train_ac.shape,y_train.shape","metadata":{"id":"bUDvfIy44w3N","outputId":"8e5149e1-9bbf-414d-f163-f4195ef6aa99","execution":{"iopub.status.busy":"2023-05-06T23:23:48.175521Z","iopub.execute_input":"2023-05-06T23:23:48.176376Z","iopub.status.idle":"2023-05-06T23:23:48.186264Z","shell.execute_reply.started":"2023-05-06T23:23:48.176335Z","shell.execute_reply":"2023-05-06T23:23:48.185050Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"((4608, 162, 1), (4608, 8))"},"metadata":{}}]},{"cell_type":"code","source":"x_test_ac.shape,y_test.shape","metadata":{"id":"ZOUi7h4_4w3O","outputId":"1f43c8bc-9c0f-40c6-9ee0-b27ce16bb56e","execution":{"iopub.status.busy":"2023-05-06T23:23:48.187842Z","iopub.execute_input":"2023-05-06T23:23:48.188188Z","iopub.status.idle":"2023-05-06T23:23:48.199423Z","shell.execute_reply.started":"2023-05-06T23:23:48.188159Z","shell.execute_reply":"2023-05-06T23:23:48.197965Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"((1152, 162, 1), (1152, 8))"},"metadata":{}}]},{"cell_type":"code","source":"rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\nhistory=model.fit(x_train_ac, y_train, batch_size=64, epochs=50, validation_data=(x_test_ac, y_test), callbacks=[rlrp])","metadata":{"id":"zFd3lUQY4w3O","outputId":"59c9038e-0893-43af-8aaa-51f0793f7ccd","execution":{"iopub.status.busy":"2023-05-06T23:23:48.201450Z","iopub.execute_input":"2023-05-06T23:23:48.201895Z","iopub.status.idle":"2023-05-06T23:27:11.245197Z","shell.execute_reply.started":"2023-05-06T23:23:48.201853Z","shell.execute_reply":"2023-05-06T23:27:11.244163Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/50\n72/72 [==============================] - 4s 45ms/step - loss: 1.8179 - accuracy: 0.2934 - val_loss: 1.6522 - val_accuracy: 0.3976 - lr: 0.0010\nEpoch 2/50\n72/72 [==============================] - 3s 47ms/step - loss: 1.6517 - accuracy: 0.3672 - val_loss: 1.5590 - val_accuracy: 0.4366 - lr: 0.0010\nEpoch 3/50\n72/72 [==============================] - 4s 51ms/step - loss: 1.5477 - accuracy: 0.4141 - val_loss: 1.4257 - val_accuracy: 0.4852 - lr: 0.0010\nEpoch 4/50\n72/72 [==============================] - 4s 52ms/step - loss: 1.4924 - accuracy: 0.4440 - val_loss: 1.4083 - val_accuracy: 0.4905 - lr: 0.0010\nEpoch 5/50\n72/72 [==============================] - 3s 44ms/step - loss: 1.4242 - accuracy: 0.4627 - val_loss: 1.3350 - val_accuracy: 0.5165 - lr: 0.0010\nEpoch 6/50\n72/72 [==============================] - 3s 46ms/step - loss: 1.3381 - accuracy: 0.4963 - val_loss: 1.2648 - val_accuracy: 0.5347 - lr: 0.0010\nEpoch 7/50\n72/72 [==============================] - 3s 40ms/step - loss: 1.3143 - accuracy: 0.5011 - val_loss: 1.2281 - val_accuracy: 0.5694 - lr: 0.0010\nEpoch 8/50\n72/72 [==============================] - 3s 39ms/step - loss: 1.2562 - accuracy: 0.5302 - val_loss: 1.1580 - val_accuracy: 0.5911 - lr: 0.0010\nEpoch 9/50\n72/72 [==============================] - 3s 40ms/step - loss: 1.2080 - accuracy: 0.5428 - val_loss: 1.1403 - val_accuracy: 0.6215 - lr: 0.0010\nEpoch 10/50\n72/72 [==============================] - 3s 42ms/step - loss: 1.1841 - accuracy: 0.5540 - val_loss: 1.0948 - val_accuracy: 0.6163 - lr: 0.0010\nEpoch 11/50\n72/72 [==============================] - 3s 43ms/step - loss: 1.1419 - accuracy: 0.5647 - val_loss: 1.0522 - val_accuracy: 0.6233 - lr: 0.0010\nEpoch 12/50\n72/72 [==============================] - 3s 41ms/step - loss: 1.1504 - accuracy: 0.5712 - val_loss: 1.0660 - val_accuracy: 0.6259 - lr: 0.0010\nEpoch 13/50\n72/72 [==============================] - 3s 45ms/step - loss: 1.1011 - accuracy: 0.5883 - val_loss: 1.0080 - val_accuracy: 0.6519 - lr: 0.0010\nEpoch 14/50\n72/72 [==============================] - 3s 47ms/step - loss: 1.0658 - accuracy: 0.6031 - val_loss: 0.9617 - val_accuracy: 0.6615 - lr: 0.0010\nEpoch 15/50\n72/72 [==============================] - 3s 46ms/step - loss: 1.0136 - accuracy: 0.6131 - val_loss: 0.9258 - val_accuracy: 0.6806 - lr: 0.0010\nEpoch 16/50\n72/72 [==============================] - 3s 47ms/step - loss: 1.0106 - accuracy: 0.6072 - val_loss: 0.9755 - val_accuracy: 0.6675 - lr: 0.0010\nEpoch 17/50\n72/72 [==============================] - 3s 48ms/step - loss: 1.0050 - accuracy: 0.6246 - val_loss: 0.9144 - val_accuracy: 0.6797 - lr: 0.0010\nEpoch 18/50\n72/72 [==============================] - 3s 43ms/step - loss: 0.9574 - accuracy: 0.6411 - val_loss: 0.8702 - val_accuracy: 0.6884 - lr: 0.0010\nEpoch 19/50\n72/72 [==============================] - 3s 45ms/step - loss: 0.9607 - accuracy: 0.6322 - val_loss: 0.8454 - val_accuracy: 0.6979 - lr: 0.0010\nEpoch 20/50\n72/72 [==============================] - 3s 47ms/step - loss: 0.9815 - accuracy: 0.6220 - val_loss: 0.9045 - val_accuracy: 0.6736 - lr: 0.0010\nEpoch 21/50\n72/72 [==============================] - 3s 46ms/step - loss: 0.8891 - accuracy: 0.6582 - val_loss: 0.8011 - val_accuracy: 0.7101 - lr: 4.0000e-04\nEpoch 22/50\n72/72 [==============================] - 3s 42ms/step - loss: 0.8540 - accuracy: 0.6721 - val_loss: 0.7912 - val_accuracy: 0.7179 - lr: 4.0000e-04\nEpoch 23/50\n72/72 [==============================] - 3s 46ms/step - loss: 0.8335 - accuracy: 0.6808 - val_loss: 0.7794 - val_accuracy: 0.7240 - lr: 4.0000e-04\nEpoch 24/50\n72/72 [==============================] - 4s 51ms/step - loss: 0.8312 - accuracy: 0.6875 - val_loss: 0.7666 - val_accuracy: 0.7413 - lr: 4.0000e-04\nEpoch 25/50\n72/72 [==============================] - 3s 47ms/step - loss: 0.8127 - accuracy: 0.6888 - val_loss: 0.7523 - val_accuracy: 0.7309 - lr: 4.0000e-04\nEpoch 26/50\n72/72 [==============================] - 3s 46ms/step - loss: 0.8030 - accuracy: 0.6918 - val_loss: 0.7335 - val_accuracy: 0.7344 - lr: 4.0000e-04\nEpoch 27/50\n72/72 [==============================] - 3s 47ms/step - loss: 0.7989 - accuracy: 0.6918 - val_loss: 0.7218 - val_accuracy: 0.7448 - lr: 4.0000e-04\nEpoch 28/50\n72/72 [==============================] - 3s 46ms/step - loss: 0.7752 - accuracy: 0.7072 - val_loss: 0.7205 - val_accuracy: 0.7387 - lr: 4.0000e-04\nEpoch 29/50\n72/72 [==============================] - 3s 46ms/step - loss: 0.7911 - accuracy: 0.6890 - val_loss: 0.7300 - val_accuracy: 0.7387 - lr: 4.0000e-04\nEpoch 30/50\n72/72 [==============================] - 3s 45ms/step - loss: 0.7840 - accuracy: 0.6977 - val_loss: 0.7291 - val_accuracy: 0.7352 - lr: 4.0000e-04\nEpoch 31/50\n72/72 [==============================] - 3s 48ms/step - loss: 0.7480 - accuracy: 0.7072 - val_loss: 0.6959 - val_accuracy: 0.7543 - lr: 1.6000e-04\nEpoch 32/50\n72/72 [==============================] - 3s 47ms/step - loss: 0.7327 - accuracy: 0.7240 - val_loss: 0.6927 - val_accuracy: 0.7439 - lr: 1.6000e-04\nEpoch 33/50\n72/72 [==============================] - 3s 48ms/step - loss: 0.7211 - accuracy: 0.7233 - val_loss: 0.6836 - val_accuracy: 0.7509 - lr: 1.6000e-04\nEpoch 34/50\n72/72 [==============================] - 3s 44ms/step - loss: 0.7420 - accuracy: 0.7120 - val_loss: 0.6783 - val_accuracy: 0.7604 - lr: 1.6000e-04\nEpoch 35/50\n72/72 [==============================] - 3s 43ms/step - loss: 0.7203 - accuracy: 0.7253 - val_loss: 0.6785 - val_accuracy: 0.7587 - lr: 1.6000e-04\nEpoch 36/50\n72/72 [==============================] - 3s 43ms/step - loss: 0.7245 - accuracy: 0.7229 - val_loss: 0.6741 - val_accuracy: 0.7509 - lr: 1.6000e-04\nEpoch 37/50\n72/72 [==============================] - 3s 46ms/step - loss: 0.7191 - accuracy: 0.7255 - val_loss: 0.6752 - val_accuracy: 0.7595 - lr: 1.6000e-04\nEpoch 38/50\n72/72 [==============================] - 3s 48ms/step - loss: 0.6985 - accuracy: 0.7307 - val_loss: 0.6665 - val_accuracy: 0.7665 - lr: 1.6000e-04\nEpoch 39/50\n72/72 [==============================] - 3s 44ms/step - loss: 0.7111 - accuracy: 0.7287 - val_loss: 0.6691 - val_accuracy: 0.7578 - lr: 1.6000e-04\nEpoch 40/50\n72/72 [==============================] - 3s 47ms/step - loss: 0.7126 - accuracy: 0.7272 - val_loss: 0.6686 - val_accuracy: 0.7604 - lr: 1.6000e-04\nEpoch 41/50\n72/72 [==============================] - 3s 44ms/step - loss: 0.6904 - accuracy: 0.7324 - val_loss: 0.6588 - val_accuracy: 0.7630 - lr: 6.4000e-05\nEpoch 42/50\n72/72 [==============================] - 3s 45ms/step - loss: 0.6897 - accuracy: 0.7329 - val_loss: 0.6583 - val_accuracy: 0.7648 - lr: 6.4000e-05\nEpoch 43/50\n72/72 [==============================] - 3s 44ms/step - loss: 0.6856 - accuracy: 0.7420 - val_loss: 0.6526 - val_accuracy: 0.7595 - lr: 6.4000e-05\nEpoch 44/50\n72/72 [==============================] - 3s 46ms/step - loss: 0.6878 - accuracy: 0.7381 - val_loss: 0.6518 - val_accuracy: 0.7595 - lr: 6.4000e-05\nEpoch 45/50\n72/72 [==============================] - 3s 44ms/step - loss: 0.6923 - accuracy: 0.7279 - val_loss: 0.6479 - val_accuracy: 0.7656 - lr: 6.4000e-05\nEpoch 46/50\n72/72 [==============================] - 3s 46ms/step - loss: 0.6947 - accuracy: 0.7357 - val_loss: 0.6466 - val_accuracy: 0.7656 - lr: 2.5600e-05\nEpoch 47/50\n72/72 [==============================] - 3s 45ms/step - loss: 0.6820 - accuracy: 0.7435 - val_loss: 0.6471 - val_accuracy: 0.7665 - lr: 2.5600e-05\nEpoch 48/50\n72/72 [==============================] - 3s 45ms/step - loss: 0.6846 - accuracy: 0.7428 - val_loss: 0.6456 - val_accuracy: 0.7665 - lr: 2.5600e-05\nEpoch 49/50\n72/72 [==============================] - 3s 44ms/step - loss: 0.6797 - accuracy: 0.7470 - val_loss: 0.6470 - val_accuracy: 0.7648 - lr: 2.5600e-05\nEpoch 50/50\n72/72 [==============================] - 3s 41ms/step - loss: 0.6837 - accuracy: 0.7368 - val_loss: 0.6442 - val_accuracy: 0.7674 - lr: 2.5600e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"# predicting on test data.\npred_test = model.predict(x_test_ac)\n# y_pred = encoder.inverse_transform(pred_test)\n\n# y_test = encoder.inverse_transform(y_test)\n# from sklearn.metrics import accuracy_score\n# accuracy = accuracy_score(y_test, pred_test)","metadata":{"id":"hYgZ7z0p4w3O","outputId":"80521db6-b987-4068-ada7-1e30ed1d0e29","execution":{"iopub.status.busy":"2023-05-06T23:28:18.235658Z","iopub.execute_input":"2023-05-06T23:28:18.236209Z","iopub.status.idle":"2023-05-06T23:28:18.622572Z","shell.execute_reply.started":"2023-05-06T23:28:18.236165Z","shell.execute_reply":"2023-05-06T23:28:18.621441Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"36/36 [==============================] - 0s 6ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate(x_test_ac,y_test)","metadata":{"id":"iDUIVQXR4w3O","outputId":"ad164a99-853e-479e-d98b-50ed2fd8b75b","execution":{"iopub.status.busy":"2023-05-06T23:28:20.486420Z","iopub.execute_input":"2023-05-06T23:28:20.486828Z","iopub.status.idle":"2023-05-06T23:28:20.866987Z","shell.execute_reply.started":"2023-05-06T23:28:20.486796Z","shell.execute_reply":"2023-05-06T23:28:20.865515Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"36/36 [==============================] - 0s 7ms/step - loss: 0.6442 - accuracy: 0.7674\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"[0.644156277179718, 0.7673611044883728]"},"metadata":{}}]},{"cell_type":"markdown","source":"### Getting the features from the Dense layer of conv1d model","metadata":{"id":"_xtc_iWP4w3O"}},{"cell_type":"code","source":"model.layers[-3]","metadata":{"id":"eArfFQjz4w3O","outputId":"90342cf4-9e36-4f6a-c4b0-415be8d9a97c","execution":{"iopub.status.busy":"2023-05-06T23:28:25.087142Z","iopub.execute_input":"2023-05-06T23:28:25.087639Z","iopub.status.idle":"2023-05-06T23:28:25.096082Z","shell.execute_reply.started":"2023-05-06T23:28:25.087594Z","shell.execute_reply":"2023-05-06T23:28:25.094504Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<keras.layers.core.dense.Dense at 0x71a73cc94580>"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\n\nconv1d_feature_model=Model(inputs=model.input,outputs=model.layers[-3].output)","metadata":{"id":"aF7BzIDF4w3O","execution":{"iopub.status.busy":"2023-05-06T23:28:25.586938Z","iopub.execute_input":"2023-05-06T23:28:25.587383Z","iopub.status.idle":"2023-05-06T23:28:26.066718Z","shell.execute_reply.started":"2023-05-06T23:28:25.587348Z","shell.execute_reply":"2023-05-06T23:28:26.065691Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"conv1d_features=conv1d_feature_model.predict(x_train_ac)","metadata":{"id":"TKz8ea3V4w3O","outputId":"8eaedad0-f4ea-4173-912c-7a5d4afa68a7","execution":{"iopub.status.busy":"2023-05-06T23:28:26.068356Z","iopub.execute_input":"2023-05-06T23:28:26.069078Z","iopub.status.idle":"2023-05-06T23:28:27.169343Z","shell.execute_reply.started":"2023-05-06T23:28:26.069031Z","shell.execute_reply":"2023-05-06T23:28:27.167825Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"144/144 [==============================] - 1s 6ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"conv1d_features_test=conv1d_feature_model.predict(x_test_ac)","metadata":{"id":"ihqAsB2n4w3O","outputId":"d3b394b2-6822-4e20-a730-6f32e15fbdaf","execution":{"iopub.status.busy":"2023-05-06T23:28:28.319138Z","iopub.execute_input":"2023-05-06T23:28:28.319588Z","iopub.status.idle":"2023-05-06T23:28:28.706796Z","shell.execute_reply.started":"2023-05-06T23:28:28.319552Z","shell.execute_reply":"2023-05-06T23:28:28.705237Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"36/36 [==============================] - 0s 7ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Concatenating with statistical features","metadata":{"id":"aJqE7Nfi4w3P"}},{"cell_type":"code","source":"x_train_gen.shape,y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:45:58.064060Z","iopub.execute_input":"2023-05-06T20:45:58.064468Z","iopub.status.idle":"2023-05-06T20:45:58.071275Z","shell.execute_reply.started":"2023-05-06T20:45:58.064436Z","shell.execute_reply":"2023-05-06T20:45:58.070156Z"},"id":"TEtk0Opx4w3P","outputId":"fe01735b-d3dc-4ecc-bd71-d645e34ebce5","trusted":true},"execution_count":null,"outputs":[{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"((4608, 1), (4608, 8))"},"metadata":{}}]},{"cell_type":"code","source":"x_train_stat.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:45:59.540173Z","iopub.execute_input":"2023-05-06T20:45:59.540567Z","iopub.status.idle":"2023-05-06T20:45:59.547690Z","shell.execute_reply.started":"2023-05-06T20:45:59.540539Z","shell.execute_reply":"2023-05-06T20:45:59.546608Z"},"id":"xKOv5e-M4w3P","outputId":"9bdc42e9-f6a9-4529-9e64-3495d4f97716","trusted":true},"execution_count":null,"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"(4608, 8, 1)"},"metadata":{}}]},{"cell_type":"code","source":"# Getting back old shape of xtrain and xtest\nx_train_stat = np.squeeze(x_train_stat)\n\n# x_train_gen = np.squeeze(x_train_gen)\nx_train_stat.shape,y_train.shape,x_train_gen.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:01.430919Z","iopub.execute_input":"2023-05-06T20:46:01.431966Z","iopub.status.idle":"2023-05-06T20:46:01.438912Z","shell.execute_reply.started":"2023-05-06T20:46:01.431925Z","shell.execute_reply":"2023-05-06T20:46:01.437809Z"},"id":"9Hrvt2S_4w3P","outputId":"51366685-3045-4f1b-f8da-f88dd1aaa6b3","trusted":true},"execution_count":null,"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"((4608, 8), (4608, 8), (4608, 1))"},"metadata":{}}]},{"cell_type":"code","source":"conv1d_features.shape,x_train_stat.shape,x_train_gen.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:02.062215Z","iopub.execute_input":"2023-05-06T20:46:02.062602Z","iopub.status.idle":"2023-05-06T20:46:02.069538Z","shell.execute_reply.started":"2023-05-06T20:46:02.062572Z","shell.execute_reply":"2023-05-06T20:46:02.068428Z"},"id":"joNEtHTH4w3P","outputId":"d024ff40-c4b0-4723-f5ec-ed140f2f2042","trusted":true},"execution_count":null,"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"((4608, 32), (4608, 8), (4608, 1))"},"metadata":{}}]},{"cell_type":"code","source":"x_train_concat=np.concatenate((conv1d_features,x_train_stat,x_train_gen),axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:03.330277Z","iopub.execute_input":"2023-05-06T20:46:03.330645Z","iopub.status.idle":"2023-05-06T20:46:03.336112Z","shell.execute_reply.started":"2023-05-06T20:46:03.330617Z","shell.execute_reply":"2023-05-06T20:46:03.334806Z"},"id":"UTTxw7Rt4w3P","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_concat.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:03.968739Z","iopub.execute_input":"2023-05-06T20:46:03.969196Z","iopub.status.idle":"2023-05-06T20:46:03.976594Z","shell.execute_reply.started":"2023-05-06T20:46:03.969151Z","shell.execute_reply":"2023-05-06T20:46:03.975305Z"},"id":"QQzjQdgo4w3P","outputId":"69a7aa40-a033-4d80-d884-ad9da60a9c0e","trusted":true},"execution_count":null,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"(4608, 41)"},"metadata":{}}]},{"cell_type":"code","source":"x_test_stat = np.squeeze(x_test_stat)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:05.284461Z","iopub.execute_input":"2023-05-06T20:46:05.285270Z","iopub.status.idle":"2023-05-06T20:46:05.290356Z","shell.execute_reply.started":"2023-05-06T20:46:05.285232Z","shell.execute_reply":"2023-05-06T20:46:05.289316Z"},"id":"O1uP7yG14w3P","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv1d_features_test.shape,x_test_stat.shape,x_test_gen.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:05.650059Z","iopub.execute_input":"2023-05-06T20:46:05.650444Z","iopub.status.idle":"2023-05-06T20:46:05.658638Z","shell.execute_reply.started":"2023-05-06T20:46:05.650409Z","shell.execute_reply":"2023-05-06T20:46:05.657538Z"},"id":"nuF6WB7e4w3P","outputId":"b39a60bb-9d51-40a4-f1af-26370ee52692","trusted":true},"execution_count":null,"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"((1152, 32), (1152, 8), (1152, 1))"},"metadata":{}}]},{"cell_type":"code","source":"x_test_concat=np.concatenate((conv1d_features_test,x_test_stat,x_test_gen),axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:06.786365Z","iopub.execute_input":"2023-05-06T20:46:06.786791Z","iopub.status.idle":"2023-05-06T20:46:06.792429Z","shell.execute_reply.started":"2023-05-06T20:46:06.786755Z","shell.execute_reply":"2023-05-06T20:46:06.791295Z"},"id":"jmmxFDzG4w3Q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test_concat.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:15.041786Z","iopub.execute_input":"2023-05-06T20:46:15.042198Z","iopub.status.idle":"2023-05-06T20:46:15.049294Z","shell.execute_reply.started":"2023-05-06T20:46:15.042155Z","shell.execute_reply":"2023-05-06T20:46:15.048204Z"},"id":"1eiu64gD4w3Q","outputId":"7f2330e9-e345-4a33-9c0b-823cc8a3be8b","trusted":true},"execution_count":null,"outputs":[{"execution_count":136,"output_type":"execute_result","data":{"text/plain":"(1152, 41)"},"metadata":{}}]},{"cell_type":"markdown","source":"## 1) Output of extracted features to Machine Learning Classification model","metadata":{"id":"VfNftxOK4w3Q"}},{"cell_type":"markdown","source":"### Classification using Random Forest","metadata":{"id":"B4qaOsR74w3Q"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:17.295420Z","iopub.execute_input":"2023-05-05T18:28:17.295821Z","iopub.status.idle":"2023-05-05T18:28:17.301469Z","shell.execute_reply.started":"2023-05-05T18:28:17.295781Z","shell.execute_reply":"2023-05-05T18:28:17.300234Z"},"id":"vH2yQHtM4w3Q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:17.594536Z","iopub.execute_input":"2023-05-05T18:28:17.594986Z","iopub.status.idle":"2023-05-05T18:28:17.601909Z","shell.execute_reply.started":"2023-05-05T18:28:17.594952Z","shell.execute_reply":"2023-05-05T18:28:17.600235Z"},"id":"rW6tNfN84w3Q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc.fit(x_train_concat, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:17.925321Z","iopub.execute_input":"2023-05-05T18:28:17.926097Z","iopub.status.idle":"2023-05-05T18:28:20.322575Z","shell.execute_reply.started":"2023-05-05T18:28:17.926056Z","shell.execute_reply":"2023-05-05T18:28:20.321548Z"},"id":"OvbHoXPo4w3Q","outputId":"c05725b3-497b-431a-b1a6-baf807d6c2ef","trusted":true},"execution_count":null,"outputs":[{"execution_count":217,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(max_depth=10, random_state=42)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = rfc.predict(x_test_concat)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:22.454171Z","iopub.execute_input":"2023-05-05T18:28:22.454605Z","iopub.status.idle":"2023-05-05T18:28:22.573214Z","shell.execute_reply.started":"2023-05-05T18:28:22.454571Z","shell.execute_reply":"2023-05-05T18:28:22.571731Z"},"id":"7w6UvT5h4w3Q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred.shape,y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:31.553344Z","iopub.execute_input":"2023-05-05T18:28:31.553792Z","iopub.status.idle":"2023-05-05T18:28:31.563698Z","shell.execute_reply.started":"2023-05-05T18:28:31.553759Z","shell.execute_reply":"2023-05-05T18:28:31.562231Z"},"id":"sYCZv14_4w3Q","outputId":"bc2581e3-e440-45a9-fa44-59610baab48c","trusted":true},"execution_count":null,"outputs":[{"execution_count":219,"output_type":"execute_result","data":{"text/plain":"((1152, 8), (1152, 8))"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:33.170444Z","iopub.execute_input":"2023-05-05T18:28:33.171112Z","iopub.status.idle":"2023-05-05T18:28:33.180973Z","shell.execute_reply.started":"2023-05-05T18:28:33.171078Z","shell.execute_reply":"2023-05-05T18:28:33.179563Z"},"id":"anGmmLDS4w3Q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:38.928160Z","iopub.execute_input":"2023-05-05T18:28:38.928578Z","iopub.status.idle":"2023-05-05T18:28:38.936660Z","shell.execute_reply.started":"2023-05-05T18:28:38.928545Z","shell.execute_reply":"2023-05-05T18:28:38.935356Z"},"id":"f1RbYGov4w3Q","outputId":"320de6d0-f61a-475d-ff71-999b60774bba","trusted":true},"execution_count":null,"outputs":[{"execution_count":221,"output_type":"execute_result","data":{"text/plain":"0.7196180555555556"},"metadata":{}}]},{"cell_type":"markdown","source":"### Just based on Deep Learning Features","metadata":{"id":"yJP6ciIt4w3R"}},{"cell_type":"code","source":"rfc.fit(conv1d_features, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:39:13.653036Z","iopub.execute_input":"2023-05-05T18:39:13.653503Z","iopub.status.idle":"2023-05-05T18:39:15.362728Z","shell.execute_reply.started":"2023-05-05T18:39:13.653469Z","shell.execute_reply":"2023-05-05T18:39:15.361398Z"},"id":"45hIBGT04w3R","outputId":"e6ea3a66-c9ee-4446-d826-df4c5ef9378a","trusted":true},"execution_count":null,"outputs":[{"execution_count":222,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(max_depth=10, random_state=42)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = rfc.predict(conv1d_features_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:40:07.805480Z","iopub.execute_input":"2023-05-05T18:40:07.805941Z","iopub.status.idle":"2023-05-05T18:40:07.932936Z","shell.execute_reply.started":"2023-05-05T18:40:07.805905Z","shell.execute_reply":"2023-05-05T18:40:07.931391Z"},"id":"UpMMd9H44w3R","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:40:21.834196Z","iopub.execute_input":"2023-05-05T18:40:21.834714Z","iopub.status.idle":"2023-05-05T18:40:21.844436Z","shell.execute_reply.started":"2023-05-05T18:40:21.834677Z","shell.execute_reply":"2023-05-05T18:40:21.843083Z"},"id":"j90jqFhk4w3R","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:40:26.804350Z","iopub.execute_input":"2023-05-05T18:40:26.804750Z","iopub.status.idle":"2023-05-05T18:40:26.812486Z","shell.execute_reply.started":"2023-05-05T18:40:26.804719Z","shell.execute_reply":"2023-05-05T18:40:26.811322Z"},"id":"6yC1X8fB4w3R","outputId":"980c34c0-1524-454c-acff-4167816ab662","trusted":true},"execution_count":null,"outputs":[{"execution_count":227,"output_type":"execute_result","data":{"text/plain":"0.7213541666666666"},"metadata":{}}]},{"cell_type":"markdown","source":"### Just based on Statistical Features","metadata":{"id":"ZE9nCgZh4w3R"}},{"cell_type":"code","source":"rfc.fit(x_train_stat, y_train)","metadata":{"id":"TI93Zbfh4w3R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = rfc.predict(x_test_stat)","metadata":{"id":"0mDGXAdj4w3R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)","metadata":{"id":"jO7ShVWm4w3R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy","metadata":{"id":"GW6JfkH94w3R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2) Extracted features to Deep Learning model ","metadata":{"id":"dtN-6shi4w3R"}},{"cell_type":"markdown","source":"### Just Based on Deep Features","metadata":{"id":"6rfos9_d4w3R"}},{"cell_type":"code","source":"pd.DataFrame(conv1d_features)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:21:43.419397Z","iopub.execute_input":"2023-05-05T19:21:43.419802Z","iopub.status.idle":"2023-05-05T19:21:43.458728Z","shell.execute_reply.started":"2023-05-05T19:21:43.419771Z","shell.execute_reply":"2023-05-05T19:21:43.457275Z"},"id":"Kj3M1WHM4w3S","outputId":"089b602f-f030-4140-f990-0d8dcf32eb96","trusted":true},"execution_count":null,"outputs":[{"execution_count":242,"output_type":"execute_result","data":{"text/plain":"            0         1    2         3    4    5         6    7         8   \\\n0     0.000000  2.411026  0.0  2.298269  0.0  0.0  2.211152  0.0  3.722932   \n1     4.174733  0.481925  0.0  1.357758  0.0  0.0  0.000000  0.0  2.500226   \n2     3.840408  0.147967  0.0  0.000000  0.0  0.0  0.000000  0.0  0.434528   \n3     0.000000  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.0  0.124334   \n4     0.000000  0.208451  0.0  8.922934  0.0  0.0  0.000000  0.0  0.000000   \n...        ...       ...  ...       ...  ...  ...       ...  ...       ...   \n4603  0.807749  0.977776  0.0  0.000000  0.0  0.0  4.784795  0.0  4.984905   \n4604  2.643344  4.106495  0.0  0.000000  0.0  0.0  2.199107  0.0  0.000000   \n4605  0.424827  0.000000  0.0  0.000000  0.0  0.0  0.875379  0.0  0.000000   \n4606  0.000000  0.000000  0.0  3.757712  0.0  0.0  3.422144  0.0  0.000000   \n4607  0.753149  0.000000  0.0  0.000000  0.0  0.0  0.019686  0.0  0.000000   \n\n            9   ...        22        23        24   25   26        27   28  \\\n0     0.000000  ...  0.222004  4.571744  0.000000  0.0  0.0  0.000000  0.0   \n1     1.420972  ...  0.000000  2.333144  0.000000  0.0  0.0  0.000000  0.0   \n2     1.629446  ...  0.244161  0.000000  0.000000  0.0  0.0  0.000000  0.0   \n3     2.250418  ...  0.000000  0.000000  0.000000  0.0  0.0  4.691520  0.0   \n4     2.805537  ...  0.000000  0.000000  0.691420  0.0  0.0  0.000000  0.0   \n...        ...  ...       ...       ...       ...  ...  ...       ...  ...   \n4603  0.000000  ...  2.489061  5.809880  3.307879  0.0  0.0  3.433646  0.0   \n4604  0.000000  ...  4.900318  5.265594  1.676853  0.0  0.0  0.000000  0.0   \n4605  0.000000  ...  0.046438  0.000000  0.504726  0.0  0.0  3.068745  0.0   \n4606  1.318160  ...  1.589476  0.000000  3.584829  0.0  0.0  0.000000  0.0   \n4607  0.544667  ...  1.863473  0.000000  1.836167  0.0  0.0  2.457544  0.0   \n\n            29        30        31  \n0     1.423667  0.000000  0.000000  \n1     1.353853  0.332708  0.000000  \n2     1.246616  3.061129  2.016101  \n3     2.616085  0.000000  0.000000  \n4     0.000000  0.000000  0.000000  \n...        ...       ...       ...  \n4603  0.000000  0.000000  0.000000  \n4604  0.000000  0.000000  5.008558  \n4605  0.000000  0.000000  0.000000  \n4606  0.070484  0.000000  0.000000  \n4607  0.000000  0.000000  0.000000  \n\n[4608 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>2.411026</td>\n      <td>0.0</td>\n      <td>2.298269</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.211152</td>\n      <td>0.0</td>\n      <td>3.722932</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.222004</td>\n      <td>4.571744</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.423667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.174733</td>\n      <td>0.481925</td>\n      <td>0.0</td>\n      <td>1.357758</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>2.500226</td>\n      <td>1.420972</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>2.333144</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.353853</td>\n      <td>0.332708</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.840408</td>\n      <td>0.147967</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.434528</td>\n      <td>1.629446</td>\n      <td>...</td>\n      <td>0.244161</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.246616</td>\n      <td>3.061129</td>\n      <td>2.016101</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.124334</td>\n      <td>2.250418</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.691520</td>\n      <td>0.0</td>\n      <td>2.616085</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.208451</td>\n      <td>0.0</td>\n      <td>8.922934</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>2.805537</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.691420</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4603</th>\n      <td>0.807749</td>\n      <td>0.977776</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.784795</td>\n      <td>0.0</td>\n      <td>4.984905</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>2.489061</td>\n      <td>5.809880</td>\n      <td>3.307879</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.433646</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4604</th>\n      <td>2.643344</td>\n      <td>4.106495</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.199107</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>4.900318</td>\n      <td>5.265594</td>\n      <td>1.676853</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.008558</td>\n    </tr>\n    <tr>\n      <th>4605</th>\n      <td>0.424827</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.875379</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.046438</td>\n      <td>0.000000</td>\n      <td>0.504726</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.068745</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4606</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>3.757712</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.422144</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.318160</td>\n      <td>...</td>\n      <td>1.589476</td>\n      <td>0.000000</td>\n      <td>3.584829</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.070484</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4607</th>\n      <td>0.753149</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.019686</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.544667</td>\n      <td>...</td>\n      <td>1.863473</td>\n      <td>0.000000</td>\n      <td>1.836167</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.457544</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>4608 rows Ã— 32 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"conv1d_features.shape,y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:25:28.372490Z","iopub.execute_input":"2023-05-05T19:25:28.372933Z","iopub.status.idle":"2023-05-05T19:25:28.381855Z","shell.execute_reply.started":"2023-05-05T19:25:28.372897Z","shell.execute_reply":"2023-05-05T19:25:28.380536Z"},"id":"fCFBX8Jm4w3S","outputId":"c4dfc41e-ced1-4868-bf07-917b9d6cca19","trusted":true},"execution_count":null,"outputs":[{"execution_count":246,"output_type":"execute_result","data":{"text/plain":"((4608, 32), (4608, 8))"},"metadata":{}}]},{"cell_type":"code","source":"model_classify = Sequential()\nmodel_classify.add(Dense(12, input_shape=(32,), activation='relu'))\nmodel_classify.add(Dense(8, activation='softmax'))\nmodel_classify.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:23:53.464804Z","iopub.execute_input":"2023-05-05T19:23:53.465225Z","iopub.status.idle":"2023-05-05T19:23:53.526471Z","shell.execute_reply.started":"2023-05-05T19:23:53.465192Z","shell.execute_reply":"2023-05-05T19:23:53.525124Z"},"id":"AuYvIFSp4w3S","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_classify.fit(conv1d_features,y_train,validation_split=0.2,epochs=50)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:26:38.062002Z","iopub.execute_input":"2023-05-05T19:26:38.062735Z","iopub.status.idle":"2023-05-05T19:26:53.985466Z","shell.execute_reply.started":"2023-05-05T19:26:38.062676Z","shell.execute_reply":"2023-05-05T19:26:53.984079Z"},"id":"MCAnG2bi4w3S","outputId":"91baf959-5cba-455c-90d0-c6795d715a76","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/50\n116/116 [==============================] - 0s 3ms/step - loss: 1.4765 - accuracy: 0.5157 - val_loss: 1.2056 - val_accuracy: 0.6204\nEpoch 2/50\n116/116 [==============================] - 0s 3ms/step - loss: 1.0556 - accuracy: 0.6712 - val_loss: 0.8966 - val_accuracy: 0.7364\nEpoch 3/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.7902 - accuracy: 0.7775 - val_loss: 0.6899 - val_accuracy: 0.8091\nEpoch 4/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.8247 - val_loss: 0.5655 - val_accuracy: 0.8243\nEpoch 5/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.8557 - val_loss: 0.4863 - val_accuracy: 0.8482\nEpoch 6/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8728 - val_loss: 0.4257 - val_accuracy: 0.8644\nEpoch 7/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.3832 - accuracy: 0.8912 - val_loss: 0.3828 - val_accuracy: 0.8883\nEpoch 8/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.9067 - val_loss: 0.3479 - val_accuracy: 0.9024\nEpoch 9/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.9143 - val_loss: 0.3212 - val_accuracy: 0.9046\nEpoch 10/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.9186 - val_loss: 0.3015 - val_accuracy: 0.9046\nEpoch 11/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2646 - accuracy: 0.9213 - val_loss: 0.2853 - val_accuracy: 0.9089\nEpoch 12/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.9286 - val_loss: 0.2765 - val_accuracy: 0.9111\nEpoch 13/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2368 - accuracy: 0.9300 - val_loss: 0.2653 - val_accuracy: 0.9111\nEpoch 14/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9322 - val_loss: 0.2544 - val_accuracy: 0.9132\nEpoch 15/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2182 - accuracy: 0.9338 - val_loss: 0.2470 - val_accuracy: 0.9143\nEpoch 16/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9349 - val_loss: 0.2411 - val_accuracy: 0.9187\nEpoch 17/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2044 - accuracy: 0.9365 - val_loss: 0.2370 - val_accuracy: 0.9197\nEpoch 18/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1981 - accuracy: 0.9365 - val_loss: 0.2328 - val_accuracy: 0.9187\nEpoch 19/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1936 - accuracy: 0.9368 - val_loss: 0.2285 - val_accuracy: 0.9230\nEpoch 20/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1893 - accuracy: 0.9368 - val_loss: 0.2245 - val_accuracy: 0.9208\nEpoch 21/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1845 - accuracy: 0.9422 - val_loss: 0.2235 - val_accuracy: 0.9219\nEpoch 22/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1808 - accuracy: 0.9444 - val_loss: 0.2185 - val_accuracy: 0.9230\nEpoch 23/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1768 - accuracy: 0.9438 - val_loss: 0.2211 - val_accuracy: 0.9208\nEpoch 24/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1743 - accuracy: 0.9414 - val_loss: 0.2130 - val_accuracy: 0.9262\nEpoch 25/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9444 - val_loss: 0.2125 - val_accuracy: 0.9295\nEpoch 26/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9449 - val_loss: 0.2116 - val_accuracy: 0.9230\nEpoch 27/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9471 - val_loss: 0.2112 - val_accuracy: 0.9241\nEpoch 28/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9444 - val_loss: 0.2076 - val_accuracy: 0.9284\nEpoch 29/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9457 - val_loss: 0.2053 - val_accuracy: 0.9273\nEpoch 30/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1590 - accuracy: 0.9474 - val_loss: 0.2043 - val_accuracy: 0.9273\nEpoch 31/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9485 - val_loss: 0.2054 - val_accuracy: 0.9252\nEpoch 32/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9482 - val_loss: 0.2053 - val_accuracy: 0.9262\nEpoch 33/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9501 - val_loss: 0.2050 - val_accuracy: 0.9306\nEpoch 34/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9487 - val_loss: 0.2026 - val_accuracy: 0.9295\nEpoch 35/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9482 - val_loss: 0.2009 - val_accuracy: 0.9306\nEpoch 36/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9493 - val_loss: 0.2030 - val_accuracy: 0.9284\nEpoch 37/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9509 - val_loss: 0.2004 - val_accuracy: 0.9295\nEpoch 38/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9504 - val_loss: 0.1980 - val_accuracy: 0.9317\nEpoch 39/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9544 - val_loss: 0.1996 - val_accuracy: 0.9328\nEpoch 40/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9525 - val_loss: 0.1983 - val_accuracy: 0.9306\nEpoch 41/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9531 - val_loss: 0.1960 - val_accuracy: 0.9349\nEpoch 42/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.9531 - val_loss: 0.1983 - val_accuracy: 0.9317\nEpoch 43/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9536 - val_loss: 0.1954 - val_accuracy: 0.9360\nEpoch 44/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1397 - accuracy: 0.9533 - val_loss: 0.1952 - val_accuracy: 0.9349\nEpoch 45/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9528 - val_loss: 0.1960 - val_accuracy: 0.9317\nEpoch 46/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9547 - val_loss: 0.1939 - val_accuracy: 0.9295\nEpoch 47/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9547 - val_loss: 0.1945 - val_accuracy: 0.9360\nEpoch 48/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.9547 - val_loss: 0.1941 - val_accuracy: 0.9349\nEpoch 49/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9555 - val_loss: 0.1949 - val_accuracy: 0.9338\nEpoch 50/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9555 - val_loss: 0.1964 - val_accuracy: 0.9306\n","output_type":"stream"},{"execution_count":248,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7616ff056290>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Based on Statistic and Deep Features","metadata":{"id":"aFWBZbvO4w3S"}},{"cell_type":"code","source":"x_test_stat.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T22:01:36.585821Z","iopub.execute_input":"2023-05-06T22:01:36.586189Z","iopub.status.idle":"2023-05-06T22:01:36.592579Z","shell.execute_reply.started":"2023-05-06T22:01:36.586162Z","shell.execute_reply":"2023-05-06T22:01:36.591622Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"(1152, 8)"},"metadata":{}}]},{"cell_type":"code","source":"stat_deep.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:28:57.618910Z","iopub.execute_input":"2023-05-05T19:28:57.619458Z","iopub.status.idle":"2023-05-05T19:28:57.627870Z","shell.execute_reply.started":"2023-05-05T19:28:57.619416Z","shell.execute_reply":"2023-05-05T19:28:57.626637Z"},"id":"von5O9324w3S","outputId":"da663808-5821-4a26-e922-60b947cfe31f","trusted":true},"execution_count":null,"outputs":[{"execution_count":251,"output_type":"execute_result","data":{"text/plain":"(4608, 40)"},"metadata":{}}]},{"cell_type":"code","source":"model_classify = Sequential()\nmodel_classify.add(Dense(12, input_shape=(40,), activation='relu'))\nmodel_classify.add(Dense(8, activation='softmax'))\nmodel_classify.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n\nmodel_classify.fit(stat_deep,y_train,validation_split=0.2,epochs=50)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:29:54.411110Z","iopub.execute_input":"2023-05-05T19:29:54.411540Z","iopub.status.idle":"2023-05-05T19:30:11.821613Z","shell.execute_reply.started":"2023-05-05T19:29:54.411506Z","shell.execute_reply":"2023-05-05T19:30:11.820279Z"},"id":"I4K6VCJF4w3S","outputId":"0f0fc6fe-e151-4b13-8a23-ddf0822b698a","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/50\n116/116 [==============================] - 1s 4ms/step - loss: 2.4467 - accuracy: 0.1994 - val_loss: 1.7715 - val_accuracy: 0.3449\nEpoch 2/50\n116/116 [==============================] - 0s 2ms/step - loss: 1.4959 - accuracy: 0.4704 - val_loss: 1.2647 - val_accuracy: 0.6041\nEpoch 3/50\n116/116 [==============================] - 0s 3ms/step - loss: 1.0602 - accuracy: 0.6910 - val_loss: 0.9034 - val_accuracy: 0.7592\nEpoch 4/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.7512 - accuracy: 0.8052 - val_loss: 0.6637 - val_accuracy: 0.8113\nEpoch 5/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.8481 - val_loss: 0.5292 - val_accuracy: 0.8525\nEpoch 6/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8728 - val_loss: 0.4521 - val_accuracy: 0.8623\nEpoch 7/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8915 - val_loss: 0.3997 - val_accuracy: 0.8796\nEpoch 8/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.9029 - val_loss: 0.3597 - val_accuracy: 0.8915\nEpoch 9/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.9132 - val_loss: 0.3328 - val_accuracy: 0.8905\nEpoch 10/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.9213 - val_loss: 0.3112 - val_accuracy: 0.9002\nEpoch 11/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.9262 - val_loss: 0.2941 - val_accuracy: 0.9013\nEpoch 12/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.9322 - val_loss: 0.2819 - val_accuracy: 0.9046\nEpoch 13/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9357 - val_loss: 0.2714 - val_accuracy: 0.9056\nEpoch 14/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9379 - val_loss: 0.2576 - val_accuracy: 0.9154\nEpoch 15/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9403 - val_loss: 0.2498 - val_accuracy: 0.9143\nEpoch 16/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9406 - val_loss: 0.2430 - val_accuracy: 0.9197\nEpoch 17/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9406 - val_loss: 0.2361 - val_accuracy: 0.9219\nEpoch 18/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1930 - accuracy: 0.9419 - val_loss: 0.2313 - val_accuracy: 0.9241\nEpoch 19/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 0.9447 - val_loss: 0.2274 - val_accuracy: 0.9252\nEpoch 20/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1814 - accuracy: 0.9452 - val_loss: 0.2208 - val_accuracy: 0.9295\nEpoch 21/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1762 - accuracy: 0.9463 - val_loss: 0.2169 - val_accuracy: 0.9262\nEpoch 22/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1724 - accuracy: 0.9452 - val_loss: 0.2128 - val_accuracy: 0.9295\nEpoch 23/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9482 - val_loss: 0.2115 - val_accuracy: 0.9295\nEpoch 24/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1639 - accuracy: 0.9487 - val_loss: 0.2076 - val_accuracy: 0.9284\nEpoch 25/50\n116/116 [==============================] - 0s 4ms/step - loss: 0.1601 - accuracy: 0.9493 - val_loss: 0.2066 - val_accuracy: 0.9295\nEpoch 26/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1571 - accuracy: 0.9506 - val_loss: 0.2043 - val_accuracy: 0.9306\nEpoch 27/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9512 - val_loss: 0.2032 - val_accuracy: 0.9317\nEpoch 28/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9517 - val_loss: 0.2025 - val_accuracy: 0.9306\nEpoch 29/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9531 - val_loss: 0.2010 - val_accuracy: 0.9306\nEpoch 30/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9528 - val_loss: 0.1989 - val_accuracy: 0.9328\nEpoch 31/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9523 - val_loss: 0.1970 - val_accuracy: 0.9295\nEpoch 32/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1424 - accuracy: 0.9520 - val_loss: 0.1981 - val_accuracy: 0.9317\nEpoch 33/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1401 - accuracy: 0.9533 - val_loss: 0.1968 - val_accuracy: 0.9317\nEpoch 34/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.9547 - val_loss: 0.1961 - val_accuracy: 0.9328\nEpoch 35/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9544 - val_loss: 0.1971 - val_accuracy: 0.9284\nEpoch 36/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9542 - val_loss: 0.1964 - val_accuracy: 0.9338\nEpoch 37/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.9552 - val_loss: 0.1973 - val_accuracy: 0.9328\nEpoch 38/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9577 - val_loss: 0.1960 - val_accuracy: 0.9306\nEpoch 39/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9571 - val_loss: 0.1957 - val_accuracy: 0.9349\nEpoch 40/50\n116/116 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9563 - val_loss: 0.1969 - val_accuracy: 0.9273\nEpoch 41/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1282 - accuracy: 0.9574 - val_loss: 0.1960 - val_accuracy: 0.9306\nEpoch 42/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9577 - val_loss: 0.1957 - val_accuracy: 0.9284\nEpoch 43/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9563 - val_loss: 0.1975 - val_accuracy: 0.9295\nEpoch 44/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9601 - val_loss: 0.1972 - val_accuracy: 0.9295\nEpoch 45/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9585 - val_loss: 0.1967 - val_accuracy: 0.9295\nEpoch 46/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9596 - val_loss: 0.1974 - val_accuracy: 0.9295\nEpoch 47/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9585 - val_loss: 0.1963 - val_accuracy: 0.9295\nEpoch 48/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9604 - val_loss: 0.1990 - val_accuracy: 0.9273\nEpoch 49/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9590 - val_loss: 0.1981 - val_accuracy: 0.9295\nEpoch 50/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1188 - accuracy: 0.9601 - val_loss: 0.1993 - val_accuracy: 0.9273\n","output_type":"stream"},{"execution_count":252,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7616fd7580a0>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Cross Validation","metadata":{}},{"cell_type":"code","source":"# Experimenting by reducing the learning rate\nfrom keras.optimizers import Adam\n\nopt = keras.optimizers.Adam(learning_rate=0.0001)","metadata":{"id":"WBou7RN-4w3S","execution":{"iopub.status.busy":"2023-05-06T23:29:00.526529Z","iopub.execute_input":"2023-05-06T23:29:00.527265Z","iopub.status.idle":"2023-05-06T23:29:00.536710Z","shell.execute_reply.started":"2023-05-06T23:29:00.527203Z","shell.execute_reply":"2023-05-06T23:29:00.534816Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"x_train_stat = np.squeeze(x_train_stat)\nx_test_stat = np.squeeze(x_test_stat)\nstat_deep=np.concatenate((conv1d_features,x_train_stat,x_train_gen),axis=1)\nstat_deep_test = np.concatenate((conv1d_features_test,x_test_stat,x_test_gen),axis=1)","metadata":{"id":"Ivpnx3Vr4w3S","execution":{"iopub.status.busy":"2023-05-06T23:28:53.048044Z","iopub.execute_input":"2023-05-06T23:28:53.048429Z","iopub.status.idle":"2023-05-06T23:28:53.054223Z","shell.execute_reply.started":"2023-05-06T23:28:53.048396Z","shell.execute_reply":"2023-05-06T23:28:53.053113Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"X_final = np.concatenate((stat_deep, stat_deep_test), axis=0)\ny_final = np.concatenate((y_train, y_test), axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T23:28:57.904388Z","iopub.execute_input":"2023-05-06T23:28:57.904878Z","iopub.status.idle":"2023-05-06T23:28:57.912793Z","shell.execute_reply.started":"2023-05-06T23:28:57.904827Z","shell.execute_reply":"2023-05-06T23:28:57.911302Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"final_df = pd.DataFrame({'X':list(X_final), 'y':list(y_final), 'actor':actors})\nfinal_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T23:29:05.959408Z","iopub.execute_input":"2023-05-06T23:29:05.959933Z","iopub.status.idle":"2023-05-06T23:29:05.985627Z","shell.execute_reply.started":"2023-05-06T23:29:05.959894Z","shell.execute_reply":"2023-05-06T23:29:05.983833Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                                                   X  \\\n0  [0.0, 0.0, 0.0, 0.0, 3.582874059677124, 0.0, 0...   \n1  [0.0, 0.0, 0.34155717492103577, 0.0, 4.5268797...   \n2  [0.0, 0.0, 0.0705176442861557, 0.0, 5.00018405...   \n3  [0.0, 0.0, 0.0, 0.0, 1.5666661262512207, 0.0, ...   \n4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n\n                                          y  actor  \n0  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]      2  \n1  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]      2  \n2  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      2  \n3  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      2  \n4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]      2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>y</th>\n      <th>actor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0.0, 0.0, 0.0, 0.0, 3.582874059677124, 0.0, 0...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0.0, 0.0, 0.34155717492103577, 0.0, 4.5268797...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0.0, 0.0, 0.0705176442861557, 0.0, 5.00018405...</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.5666661262512207, 0.0, ...</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def create_classification_model():\n    model = Sequential()\n    model.add(Dense(12, input_shape=(41,), activation='relu'))\n    model.add(Dense(8, activation='softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-06T23:29:11.945667Z","iopub.execute_input":"2023-05-06T23:29:11.946113Z","iopub.status.idle":"2023-05-06T23:29:11.952455Z","shell.execute_reply.started":"2023-05-06T23:29:11.946075Z","shell.execute_reply":"2023-05-06T23:29:11.950914Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def train_evaluate(model, X_train, y_train, X_val, y_val):\n    \n    model.compile(optimizer = opt , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n    model.fit(X_train, y_train, epochs=200, validation_data=(X_val, y_val), verbose=0)\n    model.evaluate(X_val, y_val)\n    \n    return model.evaluate(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T23:29:12.950837Z","iopub.execute_input":"2023-05-06T23:29:12.952190Z","iopub.status.idle":"2023-05-06T23:29:12.958704Z","shell.execute_reply.started":"2023-05-06T23:29:12.952127Z","shell.execute_reply":"2023-05-06T23:29:12.957335Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"actors_in_fold = []\ntrain_folds = []\ntest_fold = []\nfor i in range(6):\n    actors_in_fold.append(list(range((4*i)+1, (4*i)+5)))\n    all_folds = list(range(6))\n    all_folds.remove(i)\n    train_folds.append(all_folds)\n    test_fold.append(i)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T23:29:15.728037Z","iopub.execute_input":"2023-05-06T23:29:15.728418Z","iopub.status.idle":"2023-05-06T23:29:15.735291Z","shell.execute_reply.started":"2023-05-06T23:29:15.728387Z","shell.execute_reply":"2023-05-06T23:29:15.733987Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"print('actors_in_fold')\nprint(actors_in_fold)\nprint('train_folds')\nprint(train_folds)\nprint('test_folds')\nprint(test_fold)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T23:41:09.562956Z","iopub.execute_input":"2023-05-06T23:41:09.563429Z","iopub.status.idle":"2023-05-06T23:41:09.569984Z","shell.execute_reply.started":"2023-05-06T23:41:09.563390Z","shell.execute_reply":"2023-05-06T23:41:09.568667Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"actors_in_fold\n[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]\ntrain_folds\n[[1, 2, 3, 4, 5], [0, 2, 3, 4, 5], [0, 1, 3, 4, 5], [0, 1, 2, 4, 5], [0, 1, 2, 3, 5], [0, 1, 2, 3, 4]]\ntest_folds\n[0, 1, 2, 3, 4, 5]\n","output_type":"stream"}]},{"cell_type":"raw","source":"def cross_valiadate_actors(df):\n    for i in range(len(train_folds)):\n        print('Fold '+str(i+1)+'/'+str(6))\n        train_fold_actors = []\n        for j in train_folds[i]:\n            train_fold_actors.extend(actors_in_fold[j])\n        test_fold_actors = actors_in_fold[i]\n        train_df = df[df['actor'].isin(train_fold_actors)]\n        test_df = df[df['actor'].isin(test_fold_actors)]\n        model = create_classification_model()\n        X_train = np.stack(train_df['X'].tolist())\n        y_train = np.stack(train_df['y'].tolist())\n        X_val = np.stack(test_df['X'].tolist())\n        y_val = np.stack(test_df['y'].tolist())\n        train_evaluate(model, X_train, y_train, X_val, y_val)\n        print('Done')","metadata":{"execution":{"iopub.status.busy":"2023-05-06T23:30:23.008744Z","iopub.execute_input":"2023-05-06T23:30:23.009180Z","iopub.status.idle":"2023-05-06T23:30:23.017516Z","shell.execute_reply.started":"2023-05-06T23:30:23.009143Z","shell.execute_reply":"2023-05-06T23:30:23.016288Z"}}},{"cell_type":"code","source":"cross_valiadate_actors(final_df)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T23:30:24.094778Z","iopub.execute_input":"2023-05-06T23:30:24.095238Z","iopub.status.idle":"2023-05-06T23:38:21.452053Z","shell.execute_reply.started":"2023-05-06T23:30:24.095201Z","shell.execute_reply":"2023-05-06T23:38:21.450854Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Fold 0/6\n30/30 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8646\n30/30 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8646\nDone\nFold 1/6\n30/30 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8562\n30/30 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8562\nDone\nFold 2/6\n30/30 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8677\n30/30 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8677\nDone\nFold 3/6\n30/30 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.8406\n30/30 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.8406\nDone\nFold 4/6\n30/30 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.8375\n30/30 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.8375\nDone\nFold 5/6\n30/30 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8750\n30/30 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8750\nDone\n","output_type":"stream"}]},{"cell_type":"code","source":"model_classify = Sequential()\nmodel_classify.add(Dense(12, input_shape=(40,), activation='relu'))\nmodel_classify.add(Dense(8, activation='softmax'))\nmodel_classify.compile(optimizer = opt , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n\nmodel_classify.fit(stat_deep,y_train,validation_split=0.2,epochs=200)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:35:24.159599Z","iopub.execute_input":"2023-05-05T19:35:24.160101Z","iopub.status.idle":"2023-05-05T19:36:28.384753Z","shell.execute_reply.started":"2023-05-05T19:35:24.160058Z","shell.execute_reply":"2023-05-05T19:36:28.383146Z"},"id":"xp7xFsJ04w3S","outputId":"959978cb-69bb-490b-c62a-0b86a1b5617a","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/200\n116/116 [==============================] - 1s 4ms/step - loss: 3.2908 - accuracy: 0.1527 - val_loss: 2.5117 - val_accuracy: 0.1746\nEpoch 2/200\n116/116 [==============================] - 0s 3ms/step - loss: 2.1879 - accuracy: 0.2138 - val_loss: 1.9020 - val_accuracy: 0.2646\nEpoch 3/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.8047 - accuracy: 0.3095 - val_loss: 1.6919 - val_accuracy: 0.3623\nEpoch 4/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.6184 - accuracy: 0.3823 - val_loss: 1.5674 - val_accuracy: 0.4393\nEpoch 5/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.4943 - accuracy: 0.4533 - val_loss: 1.4740 - val_accuracy: 0.4935\nEpoch 6/200\n116/116 [==============================] - 0s 2ms/step - loss: 1.4028 - accuracy: 0.4957 - val_loss: 1.3963 - val_accuracy: 0.5239\nEpoch 7/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.3284 - accuracy: 0.5315 - val_loss: 1.3292 - val_accuracy: 0.5499\nEpoch 8/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.2638 - accuracy: 0.5665 - val_loss: 1.2703 - val_accuracy: 0.5813\nEpoch 9/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.2066 - accuracy: 0.6026 - val_loss: 1.2168 - val_accuracy: 0.6063\nEpoch 10/200\n116/116 [==============================] - 0s 2ms/step - loss: 1.1545 - accuracy: 0.6278 - val_loss: 1.1680 - val_accuracy: 0.6269\nEpoch 11/200\n116/116 [==============================] - 0s 2ms/step - loss: 1.1057 - accuracy: 0.6525 - val_loss: 1.1216 - val_accuracy: 0.6453\nEpoch 12/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.0596 - accuracy: 0.6725 - val_loss: 1.0782 - val_accuracy: 0.6627\nEpoch 13/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.0170 - accuracy: 0.6883 - val_loss: 1.0375 - val_accuracy: 0.6681\nEpoch 14/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.9771 - accuracy: 0.7013 - val_loss: 0.9991 - val_accuracy: 0.6898\nEpoch 15/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.9400 - accuracy: 0.7116 - val_loss: 0.9634 - val_accuracy: 0.7007\nEpoch 16/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.9055 - accuracy: 0.7257 - val_loss: 0.9301 - val_accuracy: 0.7180\nEpoch 17/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.8731 - accuracy: 0.7344 - val_loss: 0.8989 - val_accuracy: 0.7299\nEpoch 18/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.8425 - accuracy: 0.7450 - val_loss: 0.8692 - val_accuracy: 0.7397\nEpoch 19/200\n116/116 [==============================] - 0s 2ms/step - loss: 0.8135 - accuracy: 0.7542 - val_loss: 0.8410 - val_accuracy: 0.7505\nEpoch 20/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.7861 - accuracy: 0.7634 - val_loss: 0.8145 - val_accuracy: 0.7570\nEpoch 21/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.7600 - accuracy: 0.7737 - val_loss: 0.7887 - val_accuracy: 0.7668\nEpoch 22/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7827 - val_loss: 0.7643 - val_accuracy: 0.7722\nEpoch 23/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.7114 - accuracy: 0.7906 - val_loss: 0.7418 - val_accuracy: 0.7831\nEpoch 24/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.7965 - val_loss: 0.7203 - val_accuracy: 0.7863\nEpoch 25/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.8049 - val_loss: 0.6994 - val_accuracy: 0.7907\nEpoch 26/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.8095 - val_loss: 0.6800 - val_accuracy: 0.7993\nEpoch 27/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.8161 - val_loss: 0.6615 - val_accuracy: 0.8015\nEpoch 28/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.8180 - val_loss: 0.6438 - val_accuracy: 0.8080\nEpoch 29/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.8242 - val_loss: 0.6270 - val_accuracy: 0.8113\nEpoch 30/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.8302 - val_loss: 0.6110 - val_accuracy: 0.8134\nEpoch 31/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.8326 - val_loss: 0.5957 - val_accuracy: 0.8178\nEpoch 32/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.8370 - val_loss: 0.5811 - val_accuracy: 0.8210\nEpoch 33/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.8402 - val_loss: 0.5673 - val_accuracy: 0.8221\nEpoch 34/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.8437 - val_loss: 0.5542 - val_accuracy: 0.8243\nEpoch 35/200\n116/116 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8462 - val_loss: 0.5417 - val_accuracy: 0.8265\nEpoch 36/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.8478 - val_loss: 0.5298 - val_accuracy: 0.8319\nEpoch 37/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8519 - val_loss: 0.5183 - val_accuracy: 0.8319\nEpoch 38/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.8557 - val_loss: 0.5073 - val_accuracy: 0.8341\nEpoch 39/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.8589 - val_loss: 0.4971 - val_accuracy: 0.8395\nEpoch 40/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8587 - val_loss: 0.4872 - val_accuracy: 0.8395\nEpoch 41/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.8625 - val_loss: 0.4779 - val_accuracy: 0.8438\nEpoch 42/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8654 - val_loss: 0.4689 - val_accuracy: 0.8449\nEpoch 43/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8695 - val_loss: 0.4602 - val_accuracy: 0.8503\nEpoch 44/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8725 - val_loss: 0.4521 - val_accuracy: 0.8525\nEpoch 45/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8755 - val_loss: 0.4442 - val_accuracy: 0.8547\nEpoch 46/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8766 - val_loss: 0.4370 - val_accuracy: 0.8601\nEpoch 47/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8814 - val_loss: 0.4298 - val_accuracy: 0.8612\nEpoch 48/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8831 - val_loss: 0.4232 - val_accuracy: 0.8633\nEpoch 49/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8866 - val_loss: 0.4165 - val_accuracy: 0.8688\nEpoch 50/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8871 - val_loss: 0.4102 - val_accuracy: 0.8688\nEpoch 51/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8912 - val_loss: 0.4042 - val_accuracy: 0.8698\nEpoch 52/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8939 - val_loss: 0.3985 - val_accuracy: 0.8720\nEpoch 53/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8950 - val_loss: 0.3928 - val_accuracy: 0.8731\nEpoch 54/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8956 - val_loss: 0.3875 - val_accuracy: 0.8731\nEpoch 55/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8964 - val_loss: 0.3822 - val_accuracy: 0.8753\nEpoch 56/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8961 - val_loss: 0.3776 - val_accuracy: 0.8753\nEpoch 57/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8980 - val_loss: 0.3727 - val_accuracy: 0.8785\nEpoch 58/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8993 - val_loss: 0.3679 - val_accuracy: 0.8796\nEpoch 59/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8991 - val_loss: 0.3635 - val_accuracy: 0.8818\nEpoch 60/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.9002 - val_loss: 0.3592 - val_accuracy: 0.8829\nEpoch 61/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.9004 - val_loss: 0.3552 - val_accuracy: 0.8839\nEpoch 62/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.9004 - val_loss: 0.3510 - val_accuracy: 0.8872\nEpoch 63/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.9023 - val_loss: 0.3472 - val_accuracy: 0.8883\nEpoch 64/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3056 - accuracy: 0.9040 - val_loss: 0.3435 - val_accuracy: 0.8905\nEpoch 65/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.9048 - val_loss: 0.3399 - val_accuracy: 0.8905\nEpoch 66/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.9067 - val_loss: 0.3364 - val_accuracy: 0.8926\nEpoch 67/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.9075 - val_loss: 0.3331 - val_accuracy: 0.8926\nEpoch 68/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.9091 - val_loss: 0.3298 - val_accuracy: 0.8937\nEpoch 69/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.9094 - val_loss: 0.3264 - val_accuracy: 0.8948\nEpoch 70/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.9094 - val_loss: 0.3233 - val_accuracy: 0.8948\nEpoch 71/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.9107 - val_loss: 0.3205 - val_accuracy: 0.8959\nEpoch 72/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.9126 - val_loss: 0.3176 - val_accuracy: 0.8970\nEpoch 73/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.9145 - val_loss: 0.3148 - val_accuracy: 0.8980\nEpoch 74/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2729 - accuracy: 0.9154 - val_loss: 0.3121 - val_accuracy: 0.9002\nEpoch 75/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2702 - accuracy: 0.9164 - val_loss: 0.3095 - val_accuracy: 0.9013\nEpoch 76/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2675 - accuracy: 0.9170 - val_loss: 0.3070 - val_accuracy: 0.9002\nEpoch 77/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.9173 - val_loss: 0.3044 - val_accuracy: 0.9013\nEpoch 78/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.9175 - val_loss: 0.3018 - val_accuracy: 0.9013\nEpoch 79/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 0.9183 - val_loss: 0.2993 - val_accuracy: 0.9024\nEpoch 80/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.9186 - val_loss: 0.2970 - val_accuracy: 0.9046\nEpoch 81/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.9200 - val_loss: 0.2949 - val_accuracy: 0.9056\nEpoch 82/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.9219 - val_loss: 0.2929 - val_accuracy: 0.9067\nEpoch 83/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.9211 - val_loss: 0.2907 - val_accuracy: 0.9067\nEpoch 84/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.9216 - val_loss: 0.2884 - val_accuracy: 0.9089\nEpoch 85/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.9224 - val_loss: 0.2864 - val_accuracy: 0.9100\nEpoch 86/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.9230 - val_loss: 0.2846 - val_accuracy: 0.9100\nEpoch 87/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2425 - accuracy: 0.9240 - val_loss: 0.2829 - val_accuracy: 0.9111\nEpoch 88/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2406 - accuracy: 0.9243 - val_loss: 0.2809 - val_accuracy: 0.9111\nEpoch 89/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9243 - val_loss: 0.2792 - val_accuracy: 0.9121\nEpoch 90/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2369 - accuracy: 0.9257 - val_loss: 0.2773 - val_accuracy: 0.9121\nEpoch 91/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.9251 - val_loss: 0.2758 - val_accuracy: 0.9121\nEpoch 92/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.9259 - val_loss: 0.2741 - val_accuracy: 0.9121\nEpoch 93/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.9259 - val_loss: 0.2724 - val_accuracy: 0.9121\nEpoch 94/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9270 - val_loss: 0.2709 - val_accuracy: 0.9143\nEpoch 95/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2283 - accuracy: 0.9270 - val_loss: 0.2693 - val_accuracy: 0.9143\nEpoch 96/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2267 - accuracy: 0.9273 - val_loss: 0.2675 - val_accuracy: 0.9154\nEpoch 97/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9289 - val_loss: 0.2661 - val_accuracy: 0.9154\nEpoch 98/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9286 - val_loss: 0.2646 - val_accuracy: 0.9154\nEpoch 99/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9295 - val_loss: 0.2634 - val_accuracy: 0.9154\nEpoch 100/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.9303 - val_loss: 0.2618 - val_accuracy: 0.9165\nEpoch 101/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2192 - accuracy: 0.9305 - val_loss: 0.2605 - val_accuracy: 0.9165\nEpoch 102/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2179 - accuracy: 0.9295 - val_loss: 0.2591 - val_accuracy: 0.9165\nEpoch 103/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.9303 - val_loss: 0.2580 - val_accuracy: 0.9165\nEpoch 104/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9316 - val_loss: 0.2566 - val_accuracy: 0.9165\nEpoch 105/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9319 - val_loss: 0.2553 - val_accuracy: 0.9165\nEpoch 106/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9314 - val_loss: 0.2543 - val_accuracy: 0.9165\nEpoch 107/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9319 - val_loss: 0.2530 - val_accuracy: 0.9165\nEpoch 108/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9322 - val_loss: 0.2518 - val_accuracy: 0.9176\nEpoch 109/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9322 - val_loss: 0.2507 - val_accuracy: 0.9176\nEpoch 110/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9330 - val_loss: 0.2497 - val_accuracy: 0.9176\nEpoch 111/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2066 - accuracy: 0.9327 - val_loss: 0.2485 - val_accuracy: 0.9176\nEpoch 112/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2055 - accuracy: 0.9324 - val_loss: 0.2475 - val_accuracy: 0.9176\nEpoch 113/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2043 - accuracy: 0.9335 - val_loss: 0.2465 - val_accuracy: 0.9176\nEpoch 114/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9346 - val_loss: 0.2457 - val_accuracy: 0.9187\nEpoch 115/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2022 - accuracy: 0.9349 - val_loss: 0.2446 - val_accuracy: 0.9187\nEpoch 116/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2011 - accuracy: 0.9349 - val_loss: 0.2437 - val_accuracy: 0.9187\nEpoch 117/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 0.9354 - val_loss: 0.2426 - val_accuracy: 0.9187\nEpoch 118/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1990 - accuracy: 0.9362 - val_loss: 0.2417 - val_accuracy: 0.9187\nEpoch 119/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1981 - accuracy: 0.9365 - val_loss: 0.2407 - val_accuracy: 0.9187\nEpoch 120/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9357 - val_loss: 0.2400 - val_accuracy: 0.9208\nEpoch 121/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9376 - val_loss: 0.2391 - val_accuracy: 0.9187\nEpoch 122/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9360 - val_loss: 0.2383 - val_accuracy: 0.9197\nEpoch 123/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9362 - val_loss: 0.2373 - val_accuracy: 0.9208\nEpoch 124/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1934 - accuracy: 0.9373 - val_loss: 0.2365 - val_accuracy: 0.9219\nEpoch 125/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9371 - val_loss: 0.2358 - val_accuracy: 0.9219\nEpoch 126/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9371 - val_loss: 0.2351 - val_accuracy: 0.9219\nEpoch 127/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1907 - accuracy: 0.9379 - val_loss: 0.2343 - val_accuracy: 0.9219\nEpoch 128/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9381 - val_loss: 0.2335 - val_accuracy: 0.9219\nEpoch 129/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1890 - accuracy: 0.9384 - val_loss: 0.2327 - val_accuracy: 0.9230\nEpoch 130/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9379 - val_loss: 0.2320 - val_accuracy: 0.9241\nEpoch 131/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9376 - val_loss: 0.2315 - val_accuracy: 0.9241\nEpoch 132/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1865 - accuracy: 0.9381 - val_loss: 0.2307 - val_accuracy: 0.9241\nEpoch 133/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1857 - accuracy: 0.9387 - val_loss: 0.2300 - val_accuracy: 0.9241\nEpoch 134/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1849 - accuracy: 0.9390 - val_loss: 0.2293 - val_accuracy: 0.9241\nEpoch 135/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9387 - val_loss: 0.2286 - val_accuracy: 0.9230\nEpoch 136/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.9398 - val_loss: 0.2279 - val_accuracy: 0.9230\nEpoch 137/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1827 - accuracy: 0.9403 - val_loss: 0.2274 - val_accuracy: 0.9230\nEpoch 138/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9392 - val_loss: 0.2266 - val_accuracy: 0.9230\nEpoch 139/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1812 - accuracy: 0.9403 - val_loss: 0.2260 - val_accuracy: 0.9241\nEpoch 140/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1805 - accuracy: 0.9403 - val_loss: 0.2254 - val_accuracy: 0.9230\nEpoch 141/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1798 - accuracy: 0.9409 - val_loss: 0.2245 - val_accuracy: 0.9241\nEpoch 142/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.9409 - val_loss: 0.2239 - val_accuracy: 0.9241\nEpoch 143/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9406 - val_loss: 0.2234 - val_accuracy: 0.9241\nEpoch 144/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9409 - val_loss: 0.2230 - val_accuracy: 0.9241\nEpoch 145/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9403 - val_loss: 0.2222 - val_accuracy: 0.9219\nEpoch 146/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9411 - val_loss: 0.2218 - val_accuracy: 0.9241\nEpoch 147/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.9409 - val_loss: 0.2214 - val_accuracy: 0.9230\nEpoch 148/200\n116/116 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9414 - val_loss: 0.2206 - val_accuracy: 0.9241\nEpoch 149/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9409 - val_loss: 0.2201 - val_accuracy: 0.9241\nEpoch 150/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1739 - accuracy: 0.9411 - val_loss: 0.2196 - val_accuracy: 0.9241\nEpoch 151/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9411 - val_loss: 0.2193 - val_accuracy: 0.9252\nEpoch 152/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9419 - val_loss: 0.2187 - val_accuracy: 0.9252\nEpoch 153/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1721 - accuracy: 0.9425 - val_loss: 0.2184 - val_accuracy: 0.9252\nEpoch 154/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9436 - val_loss: 0.2179 - val_accuracy: 0.9252\nEpoch 155/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9425 - val_loss: 0.2176 - val_accuracy: 0.9252\nEpoch 156/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9425 - val_loss: 0.2170 - val_accuracy: 0.9252\nEpoch 157/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9433 - val_loss: 0.2165 - val_accuracy: 0.9252\nEpoch 158/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1692 - accuracy: 0.9430 - val_loss: 0.2159 - val_accuracy: 0.9252\nEpoch 159/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9430 - val_loss: 0.2155 - val_accuracy: 0.9252\nEpoch 160/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9438 - val_loss: 0.2150 - val_accuracy: 0.9241\nEpoch 161/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1676 - accuracy: 0.9438 - val_loss: 0.2145 - val_accuracy: 0.9241\nEpoch 162/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9452 - val_loss: 0.2143 - val_accuracy: 0.9241\nEpoch 163/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9447 - val_loss: 0.2139 - val_accuracy: 0.9252\nEpoch 164/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9441 - val_loss: 0.2132 - val_accuracy: 0.9252\nEpoch 165/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1656 - accuracy: 0.9452 - val_loss: 0.2129 - val_accuracy: 0.9241\nEpoch 166/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9447 - val_loss: 0.2124 - val_accuracy: 0.9241\nEpoch 167/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9455 - val_loss: 0.2119 - val_accuracy: 0.9230\nEpoch 168/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1640 - accuracy: 0.9460 - val_loss: 0.2116 - val_accuracy: 0.9230\nEpoch 169/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.9457 - val_loss: 0.2112 - val_accuracy: 0.9241\nEpoch 170/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9463 - val_loss: 0.2108 - val_accuracy: 0.9241\nEpoch 171/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9468 - val_loss: 0.2104 - val_accuracy: 0.9252\nEpoch 172/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9463 - val_loss: 0.2101 - val_accuracy: 0.9252\nEpoch 173/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1616 - accuracy: 0.9466 - val_loss: 0.2097 - val_accuracy: 0.9252\nEpoch 174/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9468 - val_loss: 0.2094 - val_accuracy: 0.9252\nEpoch 175/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.9471 - val_loss: 0.2090 - val_accuracy: 0.9262\nEpoch 176/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1603 - accuracy: 0.9471 - val_loss: 0.2085 - val_accuracy: 0.9252\nEpoch 177/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.9468 - val_loss: 0.2081 - val_accuracy: 0.9262\nEpoch 178/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.9460 - val_loss: 0.2078 - val_accuracy: 0.9262\nEpoch 179/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9476 - val_loss: 0.2075 - val_accuracy: 0.9262\nEpoch 180/200\n116/116 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.9471 - val_loss: 0.2070 - val_accuracy: 0.9252\nEpoch 181/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9482 - val_loss: 0.2068 - val_accuracy: 0.9262\nEpoch 182/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9471 - val_loss: 0.2063 - val_accuracy: 0.9273\nEpoch 183/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9479 - val_loss: 0.2060 - val_accuracy: 0.9273\nEpoch 184/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1568 - accuracy: 0.9471 - val_loss: 0.2056 - val_accuracy: 0.9273\nEpoch 185/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 0.9482 - val_loss: 0.2052 - val_accuracy: 0.9273\nEpoch 186/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1560 - accuracy: 0.9476 - val_loss: 0.2050 - val_accuracy: 0.9262\nEpoch 187/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9485 - val_loss: 0.2046 - val_accuracy: 0.9262\nEpoch 188/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.9487 - val_loss: 0.2042 - val_accuracy: 0.9262\nEpoch 189/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9479 - val_loss: 0.2039 - val_accuracy: 0.9262\nEpoch 190/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9485 - val_loss: 0.2038 - val_accuracy: 0.9262\nEpoch 191/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1540 - accuracy: 0.9482 - val_loss: 0.2035 - val_accuracy: 0.9262\nEpoch 192/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9479 - val_loss: 0.2032 - val_accuracy: 0.9262\nEpoch 193/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9490 - val_loss: 0.2027 - val_accuracy: 0.9273\nEpoch 194/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9493 - val_loss: 0.2022 - val_accuracy: 0.9262\nEpoch 195/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9487 - val_loss: 0.2019 - val_accuracy: 0.9273\nEpoch 196/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9482 - val_loss: 0.2017 - val_accuracy: 0.9273\nEpoch 197/200\n116/116 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9490 - val_loss: 0.2016 - val_accuracy: 0.9273\nEpoch 198/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1514 - accuracy: 0.9487 - val_loss: 0.2011 - val_accuracy: 0.9262\nEpoch 199/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9487 - val_loss: 0.2009 - val_accuracy: 0.9262\nEpoch 200/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1507 - accuracy: 0.9498 - val_loss: 0.2007 - val_accuracy: 0.9273\n","output_type":"stream"},{"execution_count":257,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7616f5200700>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"eb5wAxRE4w3S"},"execution_count":null,"outputs":[]}]}