{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  <center> Speech Emotion Recognition <center>","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nimport sys\n\n# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\nimport librosa\nimport librosa.display\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\n# to play the audio files\nfrom IPython.display import Audio\n\nimport keras\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\nfrom keras.utils import np_utils, to_categorical\nfrom keras.callbacks import ModelCheckpoint\n\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-05-06T19:47:17.174311Z","iopub.execute_input":"2023-05-06T19:47:17.174722Z","iopub.status.idle":"2023-05-06T19:47:17.183348Z","shell.execute_reply.started":"2023-05-06T19:47:17.174690Z","shell.execute_reply":"2023-05-06T19:47:17.181988Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"# Paths for data.\ndataset_path = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:47:18.664716Z","iopub.execute_input":"2023-05-06T19:47:18.665343Z","iopub.status.idle":"2023-05-06T19:47:18.669577Z","shell.execute_reply.started":"2023-05-06T19:47:18.665311Z","shell.execute_reply":"2023-05-06T19:47:18.668513Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Feature Extraction","metadata":{}},{"cell_type":"code","source":"# Adding 3 types of data augmentation techniques\ndef noise(data):\n    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n    data = data + noise_amp*np.random.normal(size=data.shape[0])\n    return data\n\ndef stretch(audio_data):\n    return librosa.effects.time_stretch(audio_data, rate=0.8)\n\ndef shift(data):\n    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n    return np.roll(data, shift_range)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:47:20.608946Z","iopub.execute_input":"2023-05-06T19:47:20.609641Z","iopub.status.idle":"2023-05-06T19:47:20.617139Z","shell.execute_reply.started":"2023-05-06T19:47:20.609599Z","shell.execute_reply":"2023-05-06T19:47:20.615947Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Function to Load data\ndef load_data(file_path):\n    audio, sampling_rate = librosa.load(file_path, duration=2.5, offset=0.6)\n    return audio","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:47:21.533134Z","iopub.execute_input":"2023-05-06T19:47:21.533983Z","iopub.status.idle":"2023-05-06T19:47:21.538713Z","shell.execute_reply.started":"2023-05-06T19:47:21.533942Z","shell.execute_reply":"2023-05-06T19:47:21.537875Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Function to preprocess the data\ndef input_label_define(dataset_path):\n    y=[]\n    X=[]\n    gender=[]\n    for folder in os.listdir(dataset_path):\n        for file in os.listdir(os.path.join(dataset_path, folder)):\n            if file.endswith('.wav'): \n                emotion = file.split('-')[2]\n                if int(emotion) == 1:\n                    label = 'Neutral'\n                elif int(emotion) == 2:\n                    label = 'Calm'\n                elif int(emotion) == 3:\n                    label = 'Happy'\n                elif int(emotion) == 4:\n                    label = 'Sad'\n                elif int(emotion) == 5:\n                    label = 'Angry'\n                elif int(emotion) == 6:\n                    label = 'Fearful'\n                elif int(emotion) == 7:\n                    label = 'Disgust'\n                elif int(emotion) == 8:\n                    label = 'Surprised'\n                else:\n                    label = 'UNK'\n                         \n                file_path = os.path.join(dataset_path, folder, file)\n                audio_array=load_data(file_path)\n                \n                # gender\n                gender_value=file_path.split(\"-\")[-1].split(\".\")[0]\n                if (int(gender_value)%2)==0:\n                    gender_feature=0\n                else:\n                    gender_feature=1\n                \n                X.append(load_data(file_path))\n                y.append(label)\n                gender.append(gender_feature)\n                \n                # data with noise\n                X.append(noise(audio_array))\n                y.append(label)\n                gender.append(gender_feature)\n                \n                # Data with shift\n                X.append(noise(audio_array))\n                y.append(label)\n                gender.append(gender_feature)\n                \n                # data with stretching and pitching\n                X.append(noise(audio_array))\n                y.append(label)\n                gender.append(gender_feature)\n            \n    return X,y,gender","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:51:03.022835Z","iopub.execute_input":"2023-05-06T19:51:03.023249Z","iopub.status.idle":"2023-05-06T19:51:03.035077Z","shell.execute_reply.started":"2023-05-06T19:51:03.023217Z","shell.execute_reply":"2023-05-06T19:51:03.033996Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"X_r_aug, y_r_aug,gender= input_label_define(dataset_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:51:03.337635Z","iopub.execute_input":"2023-05-06T19:51:03.338038Z","iopub.status.idle":"2023-05-06T19:51:45.499191Z","shell.execute_reply.started":"2023-05-06T19:51:03.338010Z","shell.execute_reply":"2023-05-06T19:51:45.498142Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"np.array(X_r_aug).shape,np.array(y_r_aug).shape,np.array(y_r_aug).shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:01:35.737397Z","iopub.execute_input":"2023-05-06T20:01:35.737961Z","iopub.status.idle":"2023-05-06T20:01:35.748914Z","shell.execute_reply.started":"2023-05-06T20:01:35.737929Z","shell.execute_reply":"2023-05-06T20:01:35.747747Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"((5760,), (5760,), (5760,))"},"metadata":{}}]},{"cell_type":"code","source":"# Saving the raw input data\n# import pickle\n\n# open a file in binary write mode\n# with open('RAVDESS_raw_aug.pkl', 'wb') as f:\n    # write the array to the file using pickle.dump()\n#     pickle.dump(np.array(X_r_aug), f)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:34:25.081538Z","iopub.execute_input":"2023-05-05T16:34:25.082431Z","iopub.status.idle":"2023-05-05T16:34:32.556903Z","shell.execute_reply.started":"2023-05-05T16:34:25.082388Z","shell.execute_reply":"2023-05-05T16:34:32.555375Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"### Extract Accoustic features","metadata":{}},{"cell_type":"code","source":"def acoustic_features(data):\n    # ZCR\n    result = np.array([])\n    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n    result=np.hstack((result, zcr)) # stacking horizontally\n\n    # Chroma_stft\n    stft = np.abs(librosa.stft(data))\n    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, chroma_stft)) # stacking horizontally\n\n    # MFCC\n    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, mfcc)) # stacking horizontally\n\n    # Root Mean Square Value\n    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n    result = np.hstack((result, rms)) # stacking horizontally\n\n    # MelSpectogram\n    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, mel)) # stacking horizontally\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:51:45.515263Z","iopub.execute_input":"2023-05-06T19:51:45.516070Z","iopub.status.idle":"2023-05-06T19:51:45.524523Z","shell.execute_reply.started":"2023-05-06T19:51:45.516037Z","shell.execute_reply":"2023-05-06T19:51:45.523645Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"sampling_rate=22050","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:02:43.633867Z","iopub.execute_input":"2023-05-06T20:02:43.634255Z","iopub.status.idle":"2023-05-06T20:02:43.639121Z","shell.execute_reply.started":"2023-05-06T20:02:43.634225Z","shell.execute_reply":"2023-05-06T20:02:43.638052Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"X_ac = []\nfor i in X_r_aug:\n    X_ac.append(acoustic_features(i))","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:51:45.542236Z","iopub.execute_input":"2023-05-06T19:51:45.542868Z","iopub.status.idle":"2023-05-06T19:59:58.091833Z","shell.execute_reply.started":"2023-05-06T19:51:45.542835Z","shell.execute_reply":"2023-05-06T19:59:58.090215Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"y_ac=y_r_aug\nnp.array(X_ac).shape,np.array(y_ac).shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:02:02.711355Z","iopub.execute_input":"2023-05-06T20:02:02.711767Z","iopub.status.idle":"2023-05-06T20:02:02.725804Z","shell.execute_reply.started":"2023-05-06T20:02:02.711733Z","shell.execute_reply":"2023-05-06T20:02:02.724891Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"((5760, 162), (5760,))"},"metadata":{}}]},{"cell_type":"code","source":"# Accoustic features saved\n# np.save('RAVDESS_Aug_Acoustic.npy',np.array(X_ac))\n# np.save('RAVDESS_Aug_Acoustic_emotion.npy',np.array(y_ac))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:32:12.745035Z","iopub.execute_input":"2023-05-05T16:32:12.745560Z","iopub.status.idle":"2023-05-05T16:32:12.772013Z","shell.execute_reply.started":"2023-05-05T16:32:12.745515Z","shell.execute_reply":"2023-05-05T16:32:12.769925Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"### Extract Statistical Features","metadata":{}},{"cell_type":"code","source":"import os, glob\nimport librosa\nimport numpy as np\nimport scipy\n\n# Function to extract features from each audio file\ndef statistical_features(audio):\n    mean = np.mean(audio)\n    variance = np.var(audio)\n    skewness = scipy.stats.skew(audio)\n    kurtosis = scipy.stats.kurtosis(audio)\n    audio_rms = librosa.feature.rms(y=audio)\n    audio_rms_mean = audio_rms.mean()\n    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sampling_rate)[0]\n    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sampling_rate)[0]\n    mfccs = librosa.feature.mfcc(y=audio, sr=sampling_rate, n_mfcc=13)\n    mfcc = mfccs.mean()\n    return [mean, variance, skewness, kurtosis, audio_rms_mean, spectral_centroids.mean(), spectral_bandwidth.mean(), mfcc]\n  ","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:59:58.129474Z","iopub.execute_input":"2023-05-06T19:59:58.130700Z","iopub.status.idle":"2023-05-06T19:59:58.145144Z","shell.execute_reply.started":"2023-05-06T19:59:58.130640Z","shell.execute_reply":"2023-05-06T19:59:58.143530Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"X_stat = []\nfor i in X_r_aug:\n    X_stat.append(statistical_features(i))\nnp.array(X_stat).shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:02:48.410645Z","iopub.execute_input":"2023-05-06T20:02:48.411026Z","iopub.status.idle":"2023-05-06T20:08:46.226820Z","shell.execute_reply.started":"2023-05-06T20:02:48.410999Z","shell.execute_reply":"2023-05-06T20:08:46.225338Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(5760, 8)"},"metadata":{}}]},{"cell_type":"code","source":"# Saving statistical features\n# np.save('RAVDESS_Aug_Stat.npy',np.array(X_stat))","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:08:46.229737Z","iopub.execute_input":"2023-05-06T20:08:46.230683Z","iopub.status.idle":"2023-05-06T20:08:46.238652Z","shell.execute_reply.started":"2023-05-06T20:08:46.230626Z","shell.execute_reply":"2023-05-06T20:08:46.237017Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"Features = pd.DataFrame(X_ac)\nFeatures['labels'] = y_ac\nFeatures.to_csv('features.csv', index=False)\nFeatures.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:08:46.241487Z","iopub.execute_input":"2023-05-06T20:08:46.242481Z","iopub.status.idle":"2023-05-06T20:08:48.202593Z","shell.execute_reply.started":"2023-05-06T20:08:46.242440Z","shell.execute_reply":"2023-05-06T20:08:48.201497Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"          0         1         2         3         4         5         6  \\\n0  0.237382  0.682273  0.670519  0.614793  0.579039  0.566803  0.637206   \n1  0.316831  0.712361  0.730024  0.709995  0.687963  0.726034  0.724934   \n2  0.285880  0.699970  0.697569  0.669696  0.650293  0.695418  0.694576   \n3  0.316935  0.705606  0.715604  0.704545  0.698203  0.731514  0.699354   \n4  0.256113  0.621621  0.580278  0.598515  0.628296  0.598015  0.597272   \n\n          7         8         9  ...       153       154       155       156  \\\n0  0.667451  0.663883  0.669903  ...  0.000234  0.000235  0.000138  0.000128   \n1  0.702700  0.680267  0.688185  ...  0.000728  0.000733  0.000626  0.000605   \n2  0.689920  0.672498  0.677640  ...  0.000290  0.000282  0.000196  0.000188   \n3  0.693375  0.681215  0.701327  ...  0.000682  0.000687  0.000625  0.000659   \n4  0.650352  0.698636  0.681863  ...  0.000018  0.000016  0.000013  0.000012   \n\n        157       158       159       160           161     labels  \n0  0.000299  0.000360  0.000275  0.000173  2.896729e-05  Surprised  \n1  0.000776  0.000842  0.000707  0.000640  5.285603e-04  Surprised  \n2  0.000349  0.000407  0.000329  0.000229  8.032456e-05  Surprised  \n3  0.000813  0.000868  0.000800  0.000627  5.330010e-04  Surprised  \n4  0.000007  0.000008  0.000008  0.000005  5.802853e-07    Neutral  \n\n[5 rows x 163 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>153</th>\n      <th>154</th>\n      <th>155</th>\n      <th>156</th>\n      <th>157</th>\n      <th>158</th>\n      <th>159</th>\n      <th>160</th>\n      <th>161</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.237382</td>\n      <td>0.682273</td>\n      <td>0.670519</td>\n      <td>0.614793</td>\n      <td>0.579039</td>\n      <td>0.566803</td>\n      <td>0.637206</td>\n      <td>0.667451</td>\n      <td>0.663883</td>\n      <td>0.669903</td>\n      <td>...</td>\n      <td>0.000234</td>\n      <td>0.000235</td>\n      <td>0.000138</td>\n      <td>0.000128</td>\n      <td>0.000299</td>\n      <td>0.000360</td>\n      <td>0.000275</td>\n      <td>0.000173</td>\n      <td>2.896729e-05</td>\n      <td>Surprised</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.316831</td>\n      <td>0.712361</td>\n      <td>0.730024</td>\n      <td>0.709995</td>\n      <td>0.687963</td>\n      <td>0.726034</td>\n      <td>0.724934</td>\n      <td>0.702700</td>\n      <td>0.680267</td>\n      <td>0.688185</td>\n      <td>...</td>\n      <td>0.000728</td>\n      <td>0.000733</td>\n      <td>0.000626</td>\n      <td>0.000605</td>\n      <td>0.000776</td>\n      <td>0.000842</td>\n      <td>0.000707</td>\n      <td>0.000640</td>\n      <td>5.285603e-04</td>\n      <td>Surprised</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.285880</td>\n      <td>0.699970</td>\n      <td>0.697569</td>\n      <td>0.669696</td>\n      <td>0.650293</td>\n      <td>0.695418</td>\n      <td>0.694576</td>\n      <td>0.689920</td>\n      <td>0.672498</td>\n      <td>0.677640</td>\n      <td>...</td>\n      <td>0.000290</td>\n      <td>0.000282</td>\n      <td>0.000196</td>\n      <td>0.000188</td>\n      <td>0.000349</td>\n      <td>0.000407</td>\n      <td>0.000329</td>\n      <td>0.000229</td>\n      <td>8.032456e-05</td>\n      <td>Surprised</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.316935</td>\n      <td>0.705606</td>\n      <td>0.715604</td>\n      <td>0.704545</td>\n      <td>0.698203</td>\n      <td>0.731514</td>\n      <td>0.699354</td>\n      <td>0.693375</td>\n      <td>0.681215</td>\n      <td>0.701327</td>\n      <td>...</td>\n      <td>0.000682</td>\n      <td>0.000687</td>\n      <td>0.000625</td>\n      <td>0.000659</td>\n      <td>0.000813</td>\n      <td>0.000868</td>\n      <td>0.000800</td>\n      <td>0.000627</td>\n      <td>5.330010e-04</td>\n      <td>Surprised</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.256113</td>\n      <td>0.621621</td>\n      <td>0.580278</td>\n      <td>0.598515</td>\n      <td>0.628296</td>\n      <td>0.598015</td>\n      <td>0.597272</td>\n      <td>0.650352</td>\n      <td>0.698636</td>\n      <td>0.681863</td>\n      <td>...</td>\n      <td>0.000018</td>\n      <td>0.000016</td>\n      <td>0.000013</td>\n      <td>0.000012</td>\n      <td>0.000007</td>\n      <td>0.000008</td>\n      <td>0.000008</td>\n      <td>0.000005</td>\n      <td>5.802853e-07</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 163 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"Features.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:08:48.205284Z","iopub.execute_input":"2023-05-06T20:08:48.206051Z","iopub.status.idle":"2023-05-06T20:08:48.214677Z","shell.execute_reply.started":"2023-05-06T20:08:48.206012Z","shell.execute_reply":"2023-05-06T20:08:48.213661Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"(5760, 163)"},"metadata":{}}]},{"cell_type":"code","source":"# Combining both statistic and deep features and gender to create a common dataframe\nstat_col_index=len(Features.columns)\nstat_features=8\nX_stat_df = pd.DataFrame(X_stat,columns=list(range(stat_col_index,stat_col_index+stat_features)))\n\ngender_col_index=len(Features.columns)+stat_features\nX_gender_df=pd.DataFrame(gender,columns=list(range(gender_col_index,gender_col_index+1)))\n# stacking horizontally for getting all combinations\nX_ac_stat_nogen = pd.concat([Features, X_stat_df], axis=1)\n\nX_ac_stat = pd.concat([Features, X_stat_df,X_gender_df], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:09:26.115008Z","iopub.execute_input":"2023-05-06T20:09:26.115641Z","iopub.status.idle":"2023-05-06T20:09:26.139047Z","shell.execute_reply.started":"2023-05-06T20:09:26.115607Z","shell.execute_reply":"2023-05-06T20:09:26.137557Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"np.array(X_ac_stat).shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:29:52.741961Z","iopub.execute_input":"2023-05-06T20:29:52.743284Z","iopub.status.idle":"2023-05-06T20:29:52.832482Z","shell.execute_reply.started":"2023-05-06T20:29:52.743235Z","shell.execute_reply":"2023-05-06T20:29:52.831537Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"(5760, 172)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"X = X_ac_stat.drop('labels',axis=1).values\nY = X_ac_stat['labels'].values","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:29:44.211325Z","iopub.execute_input":"2023-05-06T20:29:44.212347Z","iopub.status.idle":"2023-05-06T20:29:44.226324Z","shell.execute_reply.started":"2023-05-06T20:29:44.212307Z","shell.execute_reply":"2023-05-06T20:29:44.225261Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# As this is a multiclass classification problem onehotencoding our Y.\nencoder = OneHotEncoder()\nY = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:29:44.525781Z","iopub.execute_input":"2023-05-06T20:29:44.526197Z","iopub.status.idle":"2023-05-06T20:29:44.534711Z","shell.execute_reply.started":"2023-05-06T20:29:44.526162Z","shell.execute_reply":"2023-05-06T20:29:44.533525Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# splitting data\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,random_state=0, shuffle=True,stratify=Y)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:29:45.937426Z","iopub.execute_input":"2023-05-06T20:29:45.937801Z","iopub.status.idle":"2023-05-06T20:29:46.017754Z","shell.execute_reply.started":"2023-05-06T20:29:45.937776Z","shell.execute_reply":"2023-05-06T20:29:46.016524Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"((4608, 171), (4608, 8), (1152, 171), (1152, 8))"},"metadata":{}}]},{"cell_type":"code","source":"# Normalizing our data with sklearn's Standard scaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:35:09.802271Z","iopub.execute_input":"2023-05-06T20:35:09.802667Z","iopub.status.idle":"2023-05-06T20:35:09.823289Z","shell.execute_reply.started":"2023-05-06T20:35:09.802636Z","shell.execute_reply":"2023-05-06T20:35:09.822481Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"((4608, 171), (4608, 8), (1152, 171), (1152, 8))"},"metadata":{}}]},{"cell_type":"code","source":"# making our data compatible to model.\nx_train = np.expand_dims(x_train, axis=2)\nx_test = np.expand_dims(x_test, axis=2)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:35:11.210131Z","iopub.execute_input":"2023-05-06T20:35:11.210712Z","iopub.status.idle":"2023-05-06T20:35:11.217366Z","shell.execute_reply.started":"2023-05-06T20:35:11.210682Z","shell.execute_reply":"2023-05-06T20:35:11.216409Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"((4608, 171, 1), (4608, 8), (1152, 171, 1), (1152, 8))"},"metadata":{}}]},{"cell_type":"code","source":"# Acoustic feature segregation for deep feature extraction\nx_train_ac = x_train[:, :162]\nx_test_ac=x_test[:, :162]\n\nx_train_stat = x_train[:, 162:170]\nx_test_stat=x_test[:, 162:170]\n\nx_train_gen=x_train[:,-1]\nx_test_gen=x_test[:,-1]","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:45:36.656602Z","iopub.execute_input":"2023-05-06T20:45:36.657267Z","iopub.status.idle":"2023-05-06T20:45:36.663164Z","shell.execute_reply.started":"2023-05-06T20:45:36.657225Z","shell.execute_reply":"2023-05-06T20:45:36.661927Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"x_train_ac.shape,x_train_stat.shape,x_train_gen.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:45:36.922418Z","iopub.execute_input":"2023-05-06T20:45:36.922819Z","iopub.status.idle":"2023-05-06T20:45:36.929880Z","shell.execute_reply.started":"2023-05-06T20:45:36.922779Z","shell.execute_reply":"2023-05-06T20:45:36.928693Z"},"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"((4608, 162, 1), (4608, 8, 1), (4608, 1))"},"metadata":{}}]},{"cell_type":"code","source":"x_train_stat.shape,x_test_stat.shape,x_test_gen.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:45:37.303769Z","iopub.execute_input":"2023-05-06T20:45:37.304158Z","iopub.status.idle":"2023-05-06T20:45:37.311477Z","shell.execute_reply.started":"2023-05-06T20:45:37.304126Z","shell.execute_reply":"2023-05-06T20:45:37.310286Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"((4608, 8, 1), (1152, 8, 1), (1152, 1))"},"metadata":{}}]},{"cell_type":"code","source":"x_train_gen.shape,x_test_gen.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:45:37.966995Z","iopub.execute_input":"2023-05-06T20:45:37.967357Z","iopub.status.idle":"2023-05-06T20:45:37.976127Z","shell.execute_reply.started":"2023-05-06T20:45:37.967330Z","shell.execute_reply":"2023-05-06T20:45:37.972838Z"},"trusted":true},"execution_count":125,"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"((4608, 1), (1152, 1))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train_ac.shape[1], 1)))\nmodel.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=32, activation='relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(units=8, activation='softmax'))\nmodel.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:45:41.059422Z","iopub.execute_input":"2023-05-06T20:45:41.059839Z","iopub.status.idle":"2023-05-06T20:45:41.152064Z","shell.execute_reply.started":"2023-05-06T20:45:41.059805Z","shell.execute_reply":"2023-05-06T20:45:41.151472Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv1d_3 (Conv1D)           (None, 162, 256)          1536      \n                                                                 \n max_pooling1d_3 (MaxPooling  (None, 81, 256)          0         \n 1D)                                                             \n                                                                 \n flatten_3 (Flatten)         (None, 20736)             0         \n                                                                 \n dense_6 (Dense)             (None, 32)                663584    \n                                                                 \n dropout_3 (Dropout)         (None, 32)                0         \n                                                                 \n dense_7 (Dense)             (None, 8)                 264       \n                                                                 \n=================================================================\nTotal params: 665,384\nTrainable params: 665,384\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.input","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:35:33.704219Z","iopub.execute_input":"2023-05-06T20:35:33.704586Z","iopub.status.idle":"2023-05-06T20:35:33.711744Z","shell.execute_reply.started":"2023-05-06T20:35:33.704558Z","shell.execute_reply":"2023-05-06T20:35:33.710542Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"<KerasTensor: shape=(None, 162, 1) dtype=float32 (created by layer 'conv1d_2_input')>"},"metadata":{}}]},{"cell_type":"code","source":"x_train_ac.shape,y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:35:34.905335Z","iopub.execute_input":"2023-05-06T20:35:34.905695Z","iopub.status.idle":"2023-05-06T20:35:34.912505Z","shell.execute_reply.started":"2023-05-06T20:35:34.905668Z","shell.execute_reply":"2023-05-06T20:35:34.911341Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"((4608, 162, 1), (4608, 8))"},"metadata":{}}]},{"cell_type":"code","source":"x_test_ac.shape,y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:35:35.672780Z","iopub.execute_input":"2023-05-06T20:35:35.673202Z","iopub.status.idle":"2023-05-06T20:35:35.679961Z","shell.execute_reply.started":"2023-05-06T20:35:35.673169Z","shell.execute_reply":"2023-05-06T20:35:35.679012Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"((1152, 162, 1), (1152, 8))"},"metadata":{}}]},{"cell_type":"code","source":"rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\nhistory=model.fit(x_train_ac, y_train, batch_size=64, epochs=50, validation_data=(x_test_ac, y_test), callbacks=[rlrp])","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:06:16.500736Z","iopub.execute_input":"2023-05-05T19:06:16.501169Z","iopub.status.idle":"2023-05-05T19:08:39.374803Z","shell.execute_reply.started":"2023-05-05T19:06:16.501134Z","shell.execute_reply":"2023-05-05T19:08:39.373800Z"},"trusted":true},"execution_count":237,"outputs":[{"name":"stdout","text":"Epoch 1/50\n72/72 [==============================] - 4s 42ms/step - loss: 1.8112 - accuracy: 0.3001 - val_loss: 1.6303 - val_accuracy: 0.4036 - lr: 0.0010\nEpoch 2/50\n72/72 [==============================] - 3s 38ms/step - loss: 1.6053 - accuracy: 0.3800 - val_loss: 1.5032 - val_accuracy: 0.4375 - lr: 0.0010\nEpoch 3/50\n72/72 [==============================] - 3s 38ms/step - loss: 1.5123 - accuracy: 0.4275 - val_loss: 1.4187 - val_accuracy: 0.4878 - lr: 0.0010\nEpoch 4/50\n72/72 [==============================] - 3s 38ms/step - loss: 1.4337 - accuracy: 0.4586 - val_loss: 1.3480 - val_accuracy: 0.4965 - lr: 0.0010\nEpoch 5/50\n72/72 [==============================] - 3s 39ms/step - loss: 1.3892 - accuracy: 0.4770 - val_loss: 1.2679 - val_accuracy: 0.5425 - lr: 0.0010\nEpoch 6/50\n72/72 [==============================] - 3s 38ms/step - loss: 1.3047 - accuracy: 0.5074 - val_loss: 1.2191 - val_accuracy: 0.5677 - lr: 0.0010\nEpoch 7/50\n72/72 [==============================] - 3s 38ms/step - loss: 1.2530 - accuracy: 0.5252 - val_loss: 1.1652 - val_accuracy: 0.5938 - lr: 0.0010\nEpoch 8/50\n72/72 [==============================] - 3s 38ms/step - loss: 1.2388 - accuracy: 0.5317 - val_loss: 1.1179 - val_accuracy: 0.6033 - lr: 0.0010\nEpoch 9/50\n72/72 [==============================] - 3s 41ms/step - loss: 1.2010 - accuracy: 0.5460 - val_loss: 1.0962 - val_accuracy: 0.6241 - lr: 0.0010\nEpoch 10/50\n72/72 [==============================] - 3s 43ms/step - loss: 1.1472 - accuracy: 0.5684 - val_loss: 1.0724 - val_accuracy: 0.6224 - lr: 0.0010\nEpoch 11/50\n72/72 [==============================] - 3s 38ms/step - loss: 1.1039 - accuracy: 0.5831 - val_loss: 1.0290 - val_accuracy: 0.6441 - lr: 0.0010\nEpoch 12/50\n72/72 [==============================] - 3s 38ms/step - loss: 1.0664 - accuracy: 0.5970 - val_loss: 0.9641 - val_accuracy: 0.6597 - lr: 0.0010\nEpoch 13/50\n72/72 [==============================] - 3s 38ms/step - loss: 1.0280 - accuracy: 0.6131 - val_loss: 0.9395 - val_accuracy: 0.6797 - lr: 0.0010\nEpoch 14/50\n72/72 [==============================] - 3s 38ms/step - loss: 1.0016 - accuracy: 0.6246 - val_loss: 0.9218 - val_accuracy: 0.6701 - lr: 0.0010\nEpoch 15/50\n72/72 [==============================] - 3s 38ms/step - loss: 0.9934 - accuracy: 0.6200 - val_loss: 0.8772 - val_accuracy: 0.6849 - lr: 0.0010\nEpoch 16/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.9680 - accuracy: 0.6343 - val_loss: 0.8897 - val_accuracy: 0.6962 - lr: 0.0010\nEpoch 17/50\n72/72 [==============================] - 3s 38ms/step - loss: 0.9422 - accuracy: 0.6343 - val_loss: 0.8820 - val_accuracy: 0.6832 - lr: 0.0010\nEpoch 18/50\n72/72 [==============================] - 3s 40ms/step - loss: 0.9412 - accuracy: 0.6421 - val_loss: 0.8455 - val_accuracy: 0.7231 - lr: 0.0010\nEpoch 19/50\n72/72 [==============================] - 3s 40ms/step - loss: 0.8890 - accuracy: 0.6680 - val_loss: 0.8250 - val_accuracy: 0.7161 - lr: 0.0010\nEpoch 20/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.8908 - accuracy: 0.6558 - val_loss: 0.7916 - val_accuracy: 0.7161 - lr: 0.0010\nEpoch 21/50\n72/72 [==============================] - 3s 43ms/step - loss: 0.8712 - accuracy: 0.6704 - val_loss: 0.7783 - val_accuracy: 0.7352 - lr: 0.0010\nEpoch 22/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.8607 - accuracy: 0.6671 - val_loss: 0.7592 - val_accuracy: 0.7352 - lr: 0.0010\nEpoch 23/50\n72/72 [==============================] - 3s 38ms/step - loss: 0.8182 - accuracy: 0.6806 - val_loss: 0.7491 - val_accuracy: 0.7405 - lr: 0.0010\nEpoch 24/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.8541 - accuracy: 0.6727 - val_loss: 0.7707 - val_accuracy: 0.7257 - lr: 0.0010\nEpoch 25/50\n72/72 [==============================] - 3s 38ms/step - loss: 0.7917 - accuracy: 0.6986 - val_loss: 0.7150 - val_accuracy: 0.7370 - lr: 0.0010\nEpoch 26/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.8194 - accuracy: 0.6901 - val_loss: 0.7618 - val_accuracy: 0.7196 - lr: 0.0010\nEpoch 27/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.7815 - accuracy: 0.7005 - val_loss: 0.7282 - val_accuracy: 0.7300 - lr: 0.0010\nEpoch 28/50\n72/72 [==============================] - 3s 40ms/step - loss: 0.7760 - accuracy: 0.7044 - val_loss: 0.6909 - val_accuracy: 0.7569 - lr: 0.0010\nEpoch 29/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.7511 - accuracy: 0.7057 - val_loss: 0.6800 - val_accuracy: 0.7552 - lr: 0.0010\nEpoch 30/50\n72/72 [==============================] - 3s 38ms/step - loss: 0.7348 - accuracy: 0.7174 - val_loss: 0.6538 - val_accuracy: 0.7734 - lr: 0.0010\nEpoch 31/50\n72/72 [==============================] - 3s 38ms/step - loss: 0.7405 - accuracy: 0.7185 - val_loss: 0.6913 - val_accuracy: 0.7509 - lr: 0.0010\nEpoch 32/50\n72/72 [==============================] - 3s 44ms/step - loss: 0.7416 - accuracy: 0.7138 - val_loss: 0.6434 - val_accuracy: 0.7691 - lr: 0.0010\nEpoch 33/50\n72/72 [==============================] - 3s 38ms/step - loss: 0.6398 - accuracy: 0.7552 - val_loss: 0.6129 - val_accuracy: 0.7951 - lr: 4.0000e-04\nEpoch 34/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.6505 - accuracy: 0.7489 - val_loss: 0.5827 - val_accuracy: 0.7995 - lr: 4.0000e-04\nEpoch 35/50\n72/72 [==============================] - 3s 40ms/step - loss: 0.6214 - accuracy: 0.7643 - val_loss: 0.5880 - val_accuracy: 0.7917 - lr: 4.0000e-04\nEpoch 36/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.6092 - accuracy: 0.7687 - val_loss: 0.5955 - val_accuracy: 0.7865 - lr: 4.0000e-04\nEpoch 37/50\n72/72 [==============================] - 3s 40ms/step - loss: 0.5954 - accuracy: 0.7741 - val_loss: 0.5687 - val_accuracy: 0.8108 - lr: 4.0000e-04\nEpoch 38/50\n72/72 [==============================] - 3s 40ms/step - loss: 0.6053 - accuracy: 0.7697 - val_loss: 0.5689 - val_accuracy: 0.7995 - lr: 4.0000e-04\nEpoch 39/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.5798 - accuracy: 0.7786 - val_loss: 0.5559 - val_accuracy: 0.8030 - lr: 4.0000e-04\nEpoch 40/50\n72/72 [==============================] - 3s 40ms/step - loss: 0.5851 - accuracy: 0.7797 - val_loss: 0.5858 - val_accuracy: 0.7917 - lr: 4.0000e-04\nEpoch 41/50\n72/72 [==============================] - 3s 38ms/step - loss: 0.5696 - accuracy: 0.7925 - val_loss: 0.5483 - val_accuracy: 0.8082 - lr: 4.0000e-04\nEpoch 42/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.5898 - accuracy: 0.7732 - val_loss: 0.5437 - val_accuracy: 0.8064 - lr: 4.0000e-04\nEpoch 43/50\n72/72 [==============================] - 3s 43ms/step - loss: 0.5672 - accuracy: 0.7858 - val_loss: 0.5389 - val_accuracy: 0.8142 - lr: 4.0000e-04\nEpoch 44/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.5470 - accuracy: 0.7880 - val_loss: 0.5270 - val_accuracy: 0.8082 - lr: 4.0000e-04\nEpoch 45/50\n72/72 [==============================] - 3s 38ms/step - loss: 0.5596 - accuracy: 0.7862 - val_loss: 0.5218 - val_accuracy: 0.8142 - lr: 4.0000e-04\nEpoch 46/50\n72/72 [==============================] - 3s 38ms/step - loss: 0.5528 - accuracy: 0.7912 - val_loss: 0.5236 - val_accuracy: 0.8177 - lr: 4.0000e-04\nEpoch 47/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.5460 - accuracy: 0.7954 - val_loss: 0.5080 - val_accuracy: 0.8247 - lr: 1.6000e-04\nEpoch 48/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.5133 - accuracy: 0.8075 - val_loss: 0.5111 - val_accuracy: 0.8290 - lr: 1.6000e-04\nEpoch 49/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.5128 - accuracy: 0.8053 - val_loss: 0.4952 - val_accuracy: 0.8325 - lr: 1.6000e-04\nEpoch 50/50\n72/72 [==============================] - 3s 39ms/step - loss: 0.5136 - accuracy: 0.8060 - val_loss: 0.4939 - val_accuracy: 0.8420 - lr: 1.6000e-04\n","output_type":"stream"}]},{"cell_type":"code","source":"# predicting on test data.\npred_test = model.predict(x_test_ac)\n# y_pred = encoder.inverse_transform(pred_test)\n\n# y_test = encoder.inverse_transform(y_test)\n# from sklearn.metrics import accuracy_score\n# accuracy = accuracy_score(y_test, pred_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:14:37.207028Z","iopub.execute_input":"2023-05-05T19:14:37.207558Z","iopub.status.idle":"2023-05-05T19:14:37.546065Z","shell.execute_reply.started":"2023-05-05T19:14:37.207518Z","shell.execute_reply":"2023-05-05T19:14:37.544955Z"},"trusted":true},"execution_count":240,"outputs":[{"name":"stdout","text":"36/36 [==============================] - 0s 7ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate(x_test_ac,y_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:15:30.375876Z","iopub.execute_input":"2023-05-05T19:15:30.376337Z","iopub.status.idle":"2023-05-05T19:15:30.868626Z","shell.execute_reply.started":"2023-05-05T19:15:30.376305Z","shell.execute_reply":"2023-05-05T19:15:30.867685Z"},"trusted":true},"execution_count":241,"outputs":[{"name":"stdout","text":"36/36 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.8420\n","output_type":"stream"},{"execution_count":241,"output_type":"execute_result","data":{"text/plain":"[0.4939259886741638, 0.8420138955116272]"},"metadata":{}}]},{"cell_type":"markdown","source":"### Getting the features from the Dense layer of conv1d model","metadata":{}},{"cell_type":"code","source":"model.layers[-3]","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:15:59.815095Z","iopub.execute_input":"2023-05-06T20:15:59.815532Z","iopub.status.idle":"2023-05-06T20:15:59.823304Z","shell.execute_reply.started":"2023-05-06T20:15:59.815500Z","shell.execute_reply":"2023-05-06T20:15:59.822087Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"<keras.layers.core.dense.Dense at 0x7293e9555f60>"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\n\nconv1d_feature_model=Model(inputs=model.input,outputs=model.layers[-3].output)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:16:07.270158Z","iopub.execute_input":"2023-05-06T20:16:07.270515Z","iopub.status.idle":"2023-05-06T20:16:07.651404Z","shell.execute_reply.started":"2023-05-06T20:16:07.270487Z","shell.execute_reply":"2023-05-06T20:16:07.650302Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"conv1d_features=conv1d_feature_model.predict(x_train_ac)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:16:09.931048Z","iopub.execute_input":"2023-05-06T20:16:09.931469Z","iopub.status.idle":"2023-05-06T20:16:11.151821Z","shell.execute_reply.started":"2023-05-06T20:16:09.931439Z","shell.execute_reply":"2023-05-06T20:16:11.150580Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"144/144 [==============================] - 1s 5ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"conv1d_features_test=conv1d_feature_model.predict(x_test_ac)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:16:12.652578Z","iopub.execute_input":"2023-05-06T20:16:12.652999Z","iopub.status.idle":"2023-05-06T20:16:12.913438Z","shell.execute_reply.started":"2023-05-06T20:16:12.652969Z","shell.execute_reply":"2023-05-06T20:16:12.912393Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"36/36 [==============================] - 0s 5ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Concatenating with statistical features","metadata":{}},{"cell_type":"code","source":"x_train_gen.shape,y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:45:58.064060Z","iopub.execute_input":"2023-05-06T20:45:58.064468Z","iopub.status.idle":"2023-05-06T20:45:58.071275Z","shell.execute_reply.started":"2023-05-06T20:45:58.064436Z","shell.execute_reply":"2023-05-06T20:45:58.070156Z"},"trusted":true},"execution_count":127,"outputs":[{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"((4608, 1), (4608, 8))"},"metadata":{}}]},{"cell_type":"code","source":"x_train_stat.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:45:59.540173Z","iopub.execute_input":"2023-05-06T20:45:59.540567Z","iopub.status.idle":"2023-05-06T20:45:59.547690Z","shell.execute_reply.started":"2023-05-06T20:45:59.540539Z","shell.execute_reply":"2023-05-06T20:45:59.546608Z"},"trusted":true},"execution_count":128,"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"(4608, 8, 1)"},"metadata":{}}]},{"cell_type":"code","source":"# Getting back old shape of xtrain and xtest\nx_train_stat = np.squeeze(x_train_stat)\n\n# x_train_gen = np.squeeze(x_train_gen)\nx_train_stat.shape,y_train.shape,x_train_gen.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:01.430919Z","iopub.execute_input":"2023-05-06T20:46:01.431966Z","iopub.status.idle":"2023-05-06T20:46:01.438912Z","shell.execute_reply.started":"2023-05-06T20:46:01.431925Z","shell.execute_reply":"2023-05-06T20:46:01.437809Z"},"trusted":true},"execution_count":129,"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"((4608, 8), (4608, 8), (4608, 1))"},"metadata":{}}]},{"cell_type":"code","source":"conv1d_features.shape,x_train_stat.shape,x_train_gen.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:02.062215Z","iopub.execute_input":"2023-05-06T20:46:02.062602Z","iopub.status.idle":"2023-05-06T20:46:02.069538Z","shell.execute_reply.started":"2023-05-06T20:46:02.062572Z","shell.execute_reply":"2023-05-06T20:46:02.068428Z"},"trusted":true},"execution_count":130,"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"((4608, 32), (4608, 8), (4608, 1))"},"metadata":{}}]},{"cell_type":"code","source":"x_train_concat=np.concatenate((conv1d_features,x_train_stat,x_train_gen),axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:03.330277Z","iopub.execute_input":"2023-05-06T20:46:03.330645Z","iopub.status.idle":"2023-05-06T20:46:03.336112Z","shell.execute_reply.started":"2023-05-06T20:46:03.330617Z","shell.execute_reply":"2023-05-06T20:46:03.334806Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"x_train_concat.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:03.968739Z","iopub.execute_input":"2023-05-06T20:46:03.969196Z","iopub.status.idle":"2023-05-06T20:46:03.976594Z","shell.execute_reply.started":"2023-05-06T20:46:03.969151Z","shell.execute_reply":"2023-05-06T20:46:03.975305Z"},"trusted":true},"execution_count":132,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"(4608, 41)"},"metadata":{}}]},{"cell_type":"code","source":"x_test_stat = np.squeeze(x_test_stat)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:05.284461Z","iopub.execute_input":"2023-05-06T20:46:05.285270Z","iopub.status.idle":"2023-05-06T20:46:05.290356Z","shell.execute_reply.started":"2023-05-06T20:46:05.285232Z","shell.execute_reply":"2023-05-06T20:46:05.289316Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"conv1d_features_test.shape,x_test_stat.shape,x_test_gen.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:05.650059Z","iopub.execute_input":"2023-05-06T20:46:05.650444Z","iopub.status.idle":"2023-05-06T20:46:05.658638Z","shell.execute_reply.started":"2023-05-06T20:46:05.650409Z","shell.execute_reply":"2023-05-06T20:46:05.657538Z"},"trusted":true},"execution_count":134,"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"((1152, 32), (1152, 8), (1152, 1))"},"metadata":{}}]},{"cell_type":"code","source":"x_test_concat=np.concatenate((conv1d_features_test,x_test_stat,x_test_gen),axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:06.786365Z","iopub.execute_input":"2023-05-06T20:46:06.786791Z","iopub.status.idle":"2023-05-06T20:46:06.792429Z","shell.execute_reply.started":"2023-05-06T20:46:06.786755Z","shell.execute_reply":"2023-05-06T20:46:06.791295Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"x_test_concat.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-06T20:46:15.041786Z","iopub.execute_input":"2023-05-06T20:46:15.042198Z","iopub.status.idle":"2023-05-06T20:46:15.049294Z","shell.execute_reply.started":"2023-05-06T20:46:15.042155Z","shell.execute_reply":"2023-05-06T20:46:15.048204Z"},"trusted":true},"execution_count":136,"outputs":[{"execution_count":136,"output_type":"execute_result","data":{"text/plain":"(1152, 41)"},"metadata":{}}]},{"cell_type":"markdown","source":"## 1) Output of extracted features to Machine Learning Classification model","metadata":{}},{"cell_type":"markdown","source":"### Classification using Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:17.295420Z","iopub.execute_input":"2023-05-05T18:28:17.295821Z","iopub.status.idle":"2023-05-05T18:28:17.301469Z","shell.execute_reply.started":"2023-05-05T18:28:17.295781Z","shell.execute_reply":"2023-05-05T18:28:17.300234Z"},"trusted":true},"execution_count":215,"outputs":[]},{"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:17.594536Z","iopub.execute_input":"2023-05-05T18:28:17.594986Z","iopub.status.idle":"2023-05-05T18:28:17.601909Z","shell.execute_reply.started":"2023-05-05T18:28:17.594952Z","shell.execute_reply":"2023-05-05T18:28:17.600235Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"code","source":"rfc.fit(x_train_concat, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:17.925321Z","iopub.execute_input":"2023-05-05T18:28:17.926097Z","iopub.status.idle":"2023-05-05T18:28:20.322575Z","shell.execute_reply.started":"2023-05-05T18:28:17.926056Z","shell.execute_reply":"2023-05-05T18:28:20.321548Z"},"trusted":true},"execution_count":217,"outputs":[{"execution_count":217,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(max_depth=10, random_state=42)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = rfc.predict(x_test_concat)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:22.454171Z","iopub.execute_input":"2023-05-05T18:28:22.454605Z","iopub.status.idle":"2023-05-05T18:28:22.573214Z","shell.execute_reply.started":"2023-05-05T18:28:22.454571Z","shell.execute_reply":"2023-05-05T18:28:22.571731Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"y_pred.shape,y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:31.553344Z","iopub.execute_input":"2023-05-05T18:28:31.553792Z","iopub.status.idle":"2023-05-05T18:28:31.563698Z","shell.execute_reply.started":"2023-05-05T18:28:31.553759Z","shell.execute_reply":"2023-05-05T18:28:31.562231Z"},"trusted":true},"execution_count":219,"outputs":[{"execution_count":219,"output_type":"execute_result","data":{"text/plain":"((1152, 8), (1152, 8))"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:33.170444Z","iopub.execute_input":"2023-05-05T18:28:33.171112Z","iopub.status.idle":"2023-05-05T18:28:33.180973Z","shell.execute_reply.started":"2023-05-05T18:28:33.171078Z","shell.execute_reply":"2023-05-05T18:28:33.179563Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"code","source":"accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:28:38.928160Z","iopub.execute_input":"2023-05-05T18:28:38.928578Z","iopub.status.idle":"2023-05-05T18:28:38.936660Z","shell.execute_reply.started":"2023-05-05T18:28:38.928545Z","shell.execute_reply":"2023-05-05T18:28:38.935356Z"},"trusted":true},"execution_count":221,"outputs":[{"execution_count":221,"output_type":"execute_result","data":{"text/plain":"0.7196180555555556"},"metadata":{}}]},{"cell_type":"markdown","source":"### Just based on Deep Features","metadata":{}},{"cell_type":"code","source":"rfc.fit(conv1d_features, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:39:13.653036Z","iopub.execute_input":"2023-05-05T18:39:13.653503Z","iopub.status.idle":"2023-05-05T18:39:15.362728Z","shell.execute_reply.started":"2023-05-05T18:39:13.653469Z","shell.execute_reply":"2023-05-05T18:39:15.361398Z"},"trusted":true},"execution_count":222,"outputs":[{"execution_count":222,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(max_depth=10, random_state=42)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = rfc.predict(conv1d_features_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:40:07.805480Z","iopub.execute_input":"2023-05-05T18:40:07.805941Z","iopub.status.idle":"2023-05-05T18:40:07.932936Z","shell.execute_reply.started":"2023-05-05T18:40:07.805905Z","shell.execute_reply":"2023-05-05T18:40:07.931391Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:40:21.834196Z","iopub.execute_input":"2023-05-05T18:40:21.834714Z","iopub.status.idle":"2023-05-05T18:40:21.844436Z","shell.execute_reply.started":"2023-05-05T18:40:21.834677Z","shell.execute_reply":"2023-05-05T18:40:21.843083Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"code","source":"accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:40:26.804350Z","iopub.execute_input":"2023-05-05T18:40:26.804750Z","iopub.status.idle":"2023-05-05T18:40:26.812486Z","shell.execute_reply.started":"2023-05-05T18:40:26.804719Z","shell.execute_reply":"2023-05-05T18:40:26.811322Z"},"trusted":true},"execution_count":227,"outputs":[{"execution_count":227,"output_type":"execute_result","data":{"text/plain":"0.7213541666666666"},"metadata":{}}]},{"cell_type":"markdown","source":"### Just based on Deep Features","metadata":{}},{"cell_type":"code","source":"rfc.fit(x_train_stat, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = rfc.predict(x_test_stat)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2) Extracted features to Deep Learning model ","metadata":{}},{"cell_type":"markdown","source":"### Just Based on Deep Features","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(conv1d_features)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:21:43.419397Z","iopub.execute_input":"2023-05-05T19:21:43.419802Z","iopub.status.idle":"2023-05-05T19:21:43.458728Z","shell.execute_reply.started":"2023-05-05T19:21:43.419771Z","shell.execute_reply":"2023-05-05T19:21:43.457275Z"},"trusted":true},"execution_count":242,"outputs":[{"execution_count":242,"output_type":"execute_result","data":{"text/plain":"            0         1    2         3    4    5         6    7         8   \\\n0     0.000000  2.411026  0.0  2.298269  0.0  0.0  2.211152  0.0  3.722932   \n1     4.174733  0.481925  0.0  1.357758  0.0  0.0  0.000000  0.0  2.500226   \n2     3.840408  0.147967  0.0  0.000000  0.0  0.0  0.000000  0.0  0.434528   \n3     0.000000  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.0  0.124334   \n4     0.000000  0.208451  0.0  8.922934  0.0  0.0  0.000000  0.0  0.000000   \n...        ...       ...  ...       ...  ...  ...       ...  ...       ...   \n4603  0.807749  0.977776  0.0  0.000000  0.0  0.0  4.784795  0.0  4.984905   \n4604  2.643344  4.106495  0.0  0.000000  0.0  0.0  2.199107  0.0  0.000000   \n4605  0.424827  0.000000  0.0  0.000000  0.0  0.0  0.875379  0.0  0.000000   \n4606  0.000000  0.000000  0.0  3.757712  0.0  0.0  3.422144  0.0  0.000000   \n4607  0.753149  0.000000  0.0  0.000000  0.0  0.0  0.019686  0.0  0.000000   \n\n            9   ...        22        23        24   25   26        27   28  \\\n0     0.000000  ...  0.222004  4.571744  0.000000  0.0  0.0  0.000000  0.0   \n1     1.420972  ...  0.000000  2.333144  0.000000  0.0  0.0  0.000000  0.0   \n2     1.629446  ...  0.244161  0.000000  0.000000  0.0  0.0  0.000000  0.0   \n3     2.250418  ...  0.000000  0.000000  0.000000  0.0  0.0  4.691520  0.0   \n4     2.805537  ...  0.000000  0.000000  0.691420  0.0  0.0  0.000000  0.0   \n...        ...  ...       ...       ...       ...  ...  ...       ...  ...   \n4603  0.000000  ...  2.489061  5.809880  3.307879  0.0  0.0  3.433646  0.0   \n4604  0.000000  ...  4.900318  5.265594  1.676853  0.0  0.0  0.000000  0.0   \n4605  0.000000  ...  0.046438  0.000000  0.504726  0.0  0.0  3.068745  0.0   \n4606  1.318160  ...  1.589476  0.000000  3.584829  0.0  0.0  0.000000  0.0   \n4607  0.544667  ...  1.863473  0.000000  1.836167  0.0  0.0  2.457544  0.0   \n\n            29        30        31  \n0     1.423667  0.000000  0.000000  \n1     1.353853  0.332708  0.000000  \n2     1.246616  3.061129  2.016101  \n3     2.616085  0.000000  0.000000  \n4     0.000000  0.000000  0.000000  \n...        ...       ...       ...  \n4603  0.000000  0.000000  0.000000  \n4604  0.000000  0.000000  5.008558  \n4605  0.000000  0.000000  0.000000  \n4606  0.070484  0.000000  0.000000  \n4607  0.000000  0.000000  0.000000  \n\n[4608 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>2.411026</td>\n      <td>0.0</td>\n      <td>2.298269</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.211152</td>\n      <td>0.0</td>\n      <td>3.722932</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.222004</td>\n      <td>4.571744</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.423667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.174733</td>\n      <td>0.481925</td>\n      <td>0.0</td>\n      <td>1.357758</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>2.500226</td>\n      <td>1.420972</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>2.333144</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.353853</td>\n      <td>0.332708</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.840408</td>\n      <td>0.147967</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.434528</td>\n      <td>1.629446</td>\n      <td>...</td>\n      <td>0.244161</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.246616</td>\n      <td>3.061129</td>\n      <td>2.016101</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.124334</td>\n      <td>2.250418</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.691520</td>\n      <td>0.0</td>\n      <td>2.616085</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.208451</td>\n      <td>0.0</td>\n      <td>8.922934</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>2.805537</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.691420</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4603</th>\n      <td>0.807749</td>\n      <td>0.977776</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.784795</td>\n      <td>0.0</td>\n      <td>4.984905</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>2.489061</td>\n      <td>5.809880</td>\n      <td>3.307879</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.433646</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4604</th>\n      <td>2.643344</td>\n      <td>4.106495</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.199107</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>4.900318</td>\n      <td>5.265594</td>\n      <td>1.676853</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.008558</td>\n    </tr>\n    <tr>\n      <th>4605</th>\n      <td>0.424827</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.875379</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.046438</td>\n      <td>0.000000</td>\n      <td>0.504726</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.068745</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4606</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>3.757712</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.422144</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.318160</td>\n      <td>...</td>\n      <td>1.589476</td>\n      <td>0.000000</td>\n      <td>3.584829</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.070484</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4607</th>\n      <td>0.753149</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.019686</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.544667</td>\n      <td>...</td>\n      <td>1.863473</td>\n      <td>0.000000</td>\n      <td>1.836167</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.457544</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>4608 rows × 32 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"conv1d_features.shape,y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:25:28.372490Z","iopub.execute_input":"2023-05-05T19:25:28.372933Z","iopub.status.idle":"2023-05-05T19:25:28.381855Z","shell.execute_reply.started":"2023-05-05T19:25:28.372897Z","shell.execute_reply":"2023-05-05T19:25:28.380536Z"},"trusted":true},"execution_count":246,"outputs":[{"execution_count":246,"output_type":"execute_result","data":{"text/plain":"((4608, 32), (4608, 8))"},"metadata":{}}]},{"cell_type":"code","source":"model_classify = Sequential()\nmodel_classify.add(Dense(12, input_shape=(32,), activation='relu'))\nmodel_classify.add(Dense(8, activation='softmax'))\nmodel_classify.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:23:53.464804Z","iopub.execute_input":"2023-05-05T19:23:53.465225Z","iopub.status.idle":"2023-05-05T19:23:53.526471Z","shell.execute_reply.started":"2023-05-05T19:23:53.465192Z","shell.execute_reply":"2023-05-05T19:23:53.525124Z"},"trusted":true},"execution_count":244,"outputs":[]},{"cell_type":"code","source":"model_classify.fit(conv1d_features,y_train,validation_split=0.2,epochs=50)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:26:38.062002Z","iopub.execute_input":"2023-05-05T19:26:38.062735Z","iopub.status.idle":"2023-05-05T19:26:53.985466Z","shell.execute_reply.started":"2023-05-05T19:26:38.062676Z","shell.execute_reply":"2023-05-05T19:26:53.984079Z"},"trusted":true},"execution_count":248,"outputs":[{"name":"stdout","text":"Epoch 1/50\n116/116 [==============================] - 0s 3ms/step - loss: 1.4765 - accuracy: 0.5157 - val_loss: 1.2056 - val_accuracy: 0.6204\nEpoch 2/50\n116/116 [==============================] - 0s 3ms/step - loss: 1.0556 - accuracy: 0.6712 - val_loss: 0.8966 - val_accuracy: 0.7364\nEpoch 3/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.7902 - accuracy: 0.7775 - val_loss: 0.6899 - val_accuracy: 0.8091\nEpoch 4/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.8247 - val_loss: 0.5655 - val_accuracy: 0.8243\nEpoch 5/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.8557 - val_loss: 0.4863 - val_accuracy: 0.8482\nEpoch 6/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8728 - val_loss: 0.4257 - val_accuracy: 0.8644\nEpoch 7/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.3832 - accuracy: 0.8912 - val_loss: 0.3828 - val_accuracy: 0.8883\nEpoch 8/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.9067 - val_loss: 0.3479 - val_accuracy: 0.9024\nEpoch 9/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.9143 - val_loss: 0.3212 - val_accuracy: 0.9046\nEpoch 10/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.9186 - val_loss: 0.3015 - val_accuracy: 0.9046\nEpoch 11/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2646 - accuracy: 0.9213 - val_loss: 0.2853 - val_accuracy: 0.9089\nEpoch 12/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.9286 - val_loss: 0.2765 - val_accuracy: 0.9111\nEpoch 13/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2368 - accuracy: 0.9300 - val_loss: 0.2653 - val_accuracy: 0.9111\nEpoch 14/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9322 - val_loss: 0.2544 - val_accuracy: 0.9132\nEpoch 15/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2182 - accuracy: 0.9338 - val_loss: 0.2470 - val_accuracy: 0.9143\nEpoch 16/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9349 - val_loss: 0.2411 - val_accuracy: 0.9187\nEpoch 17/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2044 - accuracy: 0.9365 - val_loss: 0.2370 - val_accuracy: 0.9197\nEpoch 18/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1981 - accuracy: 0.9365 - val_loss: 0.2328 - val_accuracy: 0.9187\nEpoch 19/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1936 - accuracy: 0.9368 - val_loss: 0.2285 - val_accuracy: 0.9230\nEpoch 20/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1893 - accuracy: 0.9368 - val_loss: 0.2245 - val_accuracy: 0.9208\nEpoch 21/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1845 - accuracy: 0.9422 - val_loss: 0.2235 - val_accuracy: 0.9219\nEpoch 22/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1808 - accuracy: 0.9444 - val_loss: 0.2185 - val_accuracy: 0.9230\nEpoch 23/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1768 - accuracy: 0.9438 - val_loss: 0.2211 - val_accuracy: 0.9208\nEpoch 24/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1743 - accuracy: 0.9414 - val_loss: 0.2130 - val_accuracy: 0.9262\nEpoch 25/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9444 - val_loss: 0.2125 - val_accuracy: 0.9295\nEpoch 26/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9449 - val_loss: 0.2116 - val_accuracy: 0.9230\nEpoch 27/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9471 - val_loss: 0.2112 - val_accuracy: 0.9241\nEpoch 28/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9444 - val_loss: 0.2076 - val_accuracy: 0.9284\nEpoch 29/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9457 - val_loss: 0.2053 - val_accuracy: 0.9273\nEpoch 30/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1590 - accuracy: 0.9474 - val_loss: 0.2043 - val_accuracy: 0.9273\nEpoch 31/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9485 - val_loss: 0.2054 - val_accuracy: 0.9252\nEpoch 32/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9482 - val_loss: 0.2053 - val_accuracy: 0.9262\nEpoch 33/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9501 - val_loss: 0.2050 - val_accuracy: 0.9306\nEpoch 34/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9487 - val_loss: 0.2026 - val_accuracy: 0.9295\nEpoch 35/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9482 - val_loss: 0.2009 - val_accuracy: 0.9306\nEpoch 36/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9493 - val_loss: 0.2030 - val_accuracy: 0.9284\nEpoch 37/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9509 - val_loss: 0.2004 - val_accuracy: 0.9295\nEpoch 38/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9504 - val_loss: 0.1980 - val_accuracy: 0.9317\nEpoch 39/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9544 - val_loss: 0.1996 - val_accuracy: 0.9328\nEpoch 40/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9525 - val_loss: 0.1983 - val_accuracy: 0.9306\nEpoch 41/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9531 - val_loss: 0.1960 - val_accuracy: 0.9349\nEpoch 42/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.9531 - val_loss: 0.1983 - val_accuracy: 0.9317\nEpoch 43/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9536 - val_loss: 0.1954 - val_accuracy: 0.9360\nEpoch 44/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1397 - accuracy: 0.9533 - val_loss: 0.1952 - val_accuracy: 0.9349\nEpoch 45/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9528 - val_loss: 0.1960 - val_accuracy: 0.9317\nEpoch 46/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9547 - val_loss: 0.1939 - val_accuracy: 0.9295\nEpoch 47/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9547 - val_loss: 0.1945 - val_accuracy: 0.9360\nEpoch 48/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.9547 - val_loss: 0.1941 - val_accuracy: 0.9349\nEpoch 49/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9555 - val_loss: 0.1949 - val_accuracy: 0.9338\nEpoch 50/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9555 - val_loss: 0.1964 - val_accuracy: 0.9306\n","output_type":"stream"},{"execution_count":248,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7616ff056290>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Based on Statistic and Deep Features","metadata":{}},{"cell_type":"code","source":"stat_deep=np.concatenate((conv1d_features,x_train_stat),axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:28:46.825464Z","iopub.execute_input":"2023-05-05T19:28:46.825942Z","iopub.status.idle":"2023-05-05T19:28:46.833241Z","shell.execute_reply.started":"2023-05-05T19:28:46.825907Z","shell.execute_reply":"2023-05-05T19:28:46.832003Z"},"trusted":true},"execution_count":250,"outputs":[]},{"cell_type":"code","source":"stat_deep.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:28:57.618910Z","iopub.execute_input":"2023-05-05T19:28:57.619458Z","iopub.status.idle":"2023-05-05T19:28:57.627870Z","shell.execute_reply.started":"2023-05-05T19:28:57.619416Z","shell.execute_reply":"2023-05-05T19:28:57.626637Z"},"trusted":true},"execution_count":251,"outputs":[{"execution_count":251,"output_type":"execute_result","data":{"text/plain":"(4608, 40)"},"metadata":{}}]},{"cell_type":"code","source":"model_classify = Sequential()\nmodel_classify.add(Dense(12, input_shape=(40,), activation='relu'))\nmodel_classify.add(Dense(8, activation='softmax'))\nmodel_classify.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n\nmodel_classify.fit(stat_deep,y_train,validation_split=0.2,epochs=50)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:29:54.411110Z","iopub.execute_input":"2023-05-05T19:29:54.411540Z","iopub.status.idle":"2023-05-05T19:30:11.821613Z","shell.execute_reply.started":"2023-05-05T19:29:54.411506Z","shell.execute_reply":"2023-05-05T19:30:11.820279Z"},"trusted":true},"execution_count":252,"outputs":[{"name":"stdout","text":"Epoch 1/50\n116/116 [==============================] - 1s 4ms/step - loss: 2.4467 - accuracy: 0.1994 - val_loss: 1.7715 - val_accuracy: 0.3449\nEpoch 2/50\n116/116 [==============================] - 0s 2ms/step - loss: 1.4959 - accuracy: 0.4704 - val_loss: 1.2647 - val_accuracy: 0.6041\nEpoch 3/50\n116/116 [==============================] - 0s 3ms/step - loss: 1.0602 - accuracy: 0.6910 - val_loss: 0.9034 - val_accuracy: 0.7592\nEpoch 4/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.7512 - accuracy: 0.8052 - val_loss: 0.6637 - val_accuracy: 0.8113\nEpoch 5/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.8481 - val_loss: 0.5292 - val_accuracy: 0.8525\nEpoch 6/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8728 - val_loss: 0.4521 - val_accuracy: 0.8623\nEpoch 7/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8915 - val_loss: 0.3997 - val_accuracy: 0.8796\nEpoch 8/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.9029 - val_loss: 0.3597 - val_accuracy: 0.8915\nEpoch 9/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.9132 - val_loss: 0.3328 - val_accuracy: 0.8905\nEpoch 10/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.9213 - val_loss: 0.3112 - val_accuracy: 0.9002\nEpoch 11/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.9262 - val_loss: 0.2941 - val_accuracy: 0.9013\nEpoch 12/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.9322 - val_loss: 0.2819 - val_accuracy: 0.9046\nEpoch 13/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9357 - val_loss: 0.2714 - val_accuracy: 0.9056\nEpoch 14/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9379 - val_loss: 0.2576 - val_accuracy: 0.9154\nEpoch 15/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9403 - val_loss: 0.2498 - val_accuracy: 0.9143\nEpoch 16/50\n116/116 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9406 - val_loss: 0.2430 - val_accuracy: 0.9197\nEpoch 17/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9406 - val_loss: 0.2361 - val_accuracy: 0.9219\nEpoch 18/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1930 - accuracy: 0.9419 - val_loss: 0.2313 - val_accuracy: 0.9241\nEpoch 19/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 0.9447 - val_loss: 0.2274 - val_accuracy: 0.9252\nEpoch 20/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1814 - accuracy: 0.9452 - val_loss: 0.2208 - val_accuracy: 0.9295\nEpoch 21/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1762 - accuracy: 0.9463 - val_loss: 0.2169 - val_accuracy: 0.9262\nEpoch 22/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1724 - accuracy: 0.9452 - val_loss: 0.2128 - val_accuracy: 0.9295\nEpoch 23/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9482 - val_loss: 0.2115 - val_accuracy: 0.9295\nEpoch 24/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1639 - accuracy: 0.9487 - val_loss: 0.2076 - val_accuracy: 0.9284\nEpoch 25/50\n116/116 [==============================] - 0s 4ms/step - loss: 0.1601 - accuracy: 0.9493 - val_loss: 0.2066 - val_accuracy: 0.9295\nEpoch 26/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1571 - accuracy: 0.9506 - val_loss: 0.2043 - val_accuracy: 0.9306\nEpoch 27/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9512 - val_loss: 0.2032 - val_accuracy: 0.9317\nEpoch 28/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9517 - val_loss: 0.2025 - val_accuracy: 0.9306\nEpoch 29/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9531 - val_loss: 0.2010 - val_accuracy: 0.9306\nEpoch 30/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9528 - val_loss: 0.1989 - val_accuracy: 0.9328\nEpoch 31/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9523 - val_loss: 0.1970 - val_accuracy: 0.9295\nEpoch 32/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1424 - accuracy: 0.9520 - val_loss: 0.1981 - val_accuracy: 0.9317\nEpoch 33/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1401 - accuracy: 0.9533 - val_loss: 0.1968 - val_accuracy: 0.9317\nEpoch 34/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.9547 - val_loss: 0.1961 - val_accuracy: 0.9328\nEpoch 35/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9544 - val_loss: 0.1971 - val_accuracy: 0.9284\nEpoch 36/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9542 - val_loss: 0.1964 - val_accuracy: 0.9338\nEpoch 37/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.9552 - val_loss: 0.1973 - val_accuracy: 0.9328\nEpoch 38/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9577 - val_loss: 0.1960 - val_accuracy: 0.9306\nEpoch 39/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9571 - val_loss: 0.1957 - val_accuracy: 0.9349\nEpoch 40/50\n116/116 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9563 - val_loss: 0.1969 - val_accuracy: 0.9273\nEpoch 41/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1282 - accuracy: 0.9574 - val_loss: 0.1960 - val_accuracy: 0.9306\nEpoch 42/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9577 - val_loss: 0.1957 - val_accuracy: 0.9284\nEpoch 43/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9563 - val_loss: 0.1975 - val_accuracy: 0.9295\nEpoch 44/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9601 - val_loss: 0.1972 - val_accuracy: 0.9295\nEpoch 45/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9585 - val_loss: 0.1967 - val_accuracy: 0.9295\nEpoch 46/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9596 - val_loss: 0.1974 - val_accuracy: 0.9295\nEpoch 47/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9585 - val_loss: 0.1963 - val_accuracy: 0.9295\nEpoch 48/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9604 - val_loss: 0.1990 - val_accuracy: 0.9273\nEpoch 49/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9590 - val_loss: 0.1981 - val_accuracy: 0.9295\nEpoch 50/50\n116/116 [==============================] - 0s 3ms/step - loss: 0.1188 - accuracy: 0.9601 - val_loss: 0.1993 - val_accuracy: 0.9273\n","output_type":"stream"},{"execution_count":252,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7616fd7580a0>"},"metadata":{}}]},{"cell_type":"code","source":"# Experimenting by reducing the learning rate\nfrom keras.optimizers import Adam\n\nopt = keras.optimizers.Adam(learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:33:54.409951Z","iopub.execute_input":"2023-05-05T19:33:54.410476Z","iopub.status.idle":"2023-05-05T19:33:54.417801Z","shell.execute_reply.started":"2023-05-05T19:33:54.410439Z","shell.execute_reply":"2023-05-05T19:33:54.416068Z"},"trusted":true},"execution_count":253,"outputs":[]},{"cell_type":"code","source":"model_classify = Sequential()\nmodel_classify.add(Dense(12, input_shape=(40,), activation='relu'))\nmodel_classify.add(Dense(8, activation='softmax'))\nmodel_classify.compile(optimizer = opt , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n\nmodel_classify.fit(stat_deep,y_train,validation_split=0.2,epochs=200)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T19:35:24.159599Z","iopub.execute_input":"2023-05-05T19:35:24.160101Z","iopub.status.idle":"2023-05-05T19:36:28.384753Z","shell.execute_reply.started":"2023-05-05T19:35:24.160058Z","shell.execute_reply":"2023-05-05T19:36:28.383146Z"},"trusted":true},"execution_count":257,"outputs":[{"name":"stdout","text":"Epoch 1/200\n116/116 [==============================] - 1s 4ms/step - loss: 3.2908 - accuracy: 0.1527 - val_loss: 2.5117 - val_accuracy: 0.1746\nEpoch 2/200\n116/116 [==============================] - 0s 3ms/step - loss: 2.1879 - accuracy: 0.2138 - val_loss: 1.9020 - val_accuracy: 0.2646\nEpoch 3/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.8047 - accuracy: 0.3095 - val_loss: 1.6919 - val_accuracy: 0.3623\nEpoch 4/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.6184 - accuracy: 0.3823 - val_loss: 1.5674 - val_accuracy: 0.4393\nEpoch 5/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.4943 - accuracy: 0.4533 - val_loss: 1.4740 - val_accuracy: 0.4935\nEpoch 6/200\n116/116 [==============================] - 0s 2ms/step - loss: 1.4028 - accuracy: 0.4957 - val_loss: 1.3963 - val_accuracy: 0.5239\nEpoch 7/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.3284 - accuracy: 0.5315 - val_loss: 1.3292 - val_accuracy: 0.5499\nEpoch 8/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.2638 - accuracy: 0.5665 - val_loss: 1.2703 - val_accuracy: 0.5813\nEpoch 9/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.2066 - accuracy: 0.6026 - val_loss: 1.2168 - val_accuracy: 0.6063\nEpoch 10/200\n116/116 [==============================] - 0s 2ms/step - loss: 1.1545 - accuracy: 0.6278 - val_loss: 1.1680 - val_accuracy: 0.6269\nEpoch 11/200\n116/116 [==============================] - 0s 2ms/step - loss: 1.1057 - accuracy: 0.6525 - val_loss: 1.1216 - val_accuracy: 0.6453\nEpoch 12/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.0596 - accuracy: 0.6725 - val_loss: 1.0782 - val_accuracy: 0.6627\nEpoch 13/200\n116/116 [==============================] - 0s 3ms/step - loss: 1.0170 - accuracy: 0.6883 - val_loss: 1.0375 - val_accuracy: 0.6681\nEpoch 14/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.9771 - accuracy: 0.7013 - val_loss: 0.9991 - val_accuracy: 0.6898\nEpoch 15/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.9400 - accuracy: 0.7116 - val_loss: 0.9634 - val_accuracy: 0.7007\nEpoch 16/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.9055 - accuracy: 0.7257 - val_loss: 0.9301 - val_accuracy: 0.7180\nEpoch 17/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.8731 - accuracy: 0.7344 - val_loss: 0.8989 - val_accuracy: 0.7299\nEpoch 18/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.8425 - accuracy: 0.7450 - val_loss: 0.8692 - val_accuracy: 0.7397\nEpoch 19/200\n116/116 [==============================] - 0s 2ms/step - loss: 0.8135 - accuracy: 0.7542 - val_loss: 0.8410 - val_accuracy: 0.7505\nEpoch 20/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.7861 - accuracy: 0.7634 - val_loss: 0.8145 - val_accuracy: 0.7570\nEpoch 21/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.7600 - accuracy: 0.7737 - val_loss: 0.7887 - val_accuracy: 0.7668\nEpoch 22/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.7827 - val_loss: 0.7643 - val_accuracy: 0.7722\nEpoch 23/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.7114 - accuracy: 0.7906 - val_loss: 0.7418 - val_accuracy: 0.7831\nEpoch 24/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.7965 - val_loss: 0.7203 - val_accuracy: 0.7863\nEpoch 25/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.8049 - val_loss: 0.6994 - val_accuracy: 0.7907\nEpoch 26/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.8095 - val_loss: 0.6800 - val_accuracy: 0.7993\nEpoch 27/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.8161 - val_loss: 0.6615 - val_accuracy: 0.8015\nEpoch 28/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.8180 - val_loss: 0.6438 - val_accuracy: 0.8080\nEpoch 29/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.8242 - val_loss: 0.6270 - val_accuracy: 0.8113\nEpoch 30/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.8302 - val_loss: 0.6110 - val_accuracy: 0.8134\nEpoch 31/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.8326 - val_loss: 0.5957 - val_accuracy: 0.8178\nEpoch 32/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.8370 - val_loss: 0.5811 - val_accuracy: 0.8210\nEpoch 33/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.8402 - val_loss: 0.5673 - val_accuracy: 0.8221\nEpoch 34/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.8437 - val_loss: 0.5542 - val_accuracy: 0.8243\nEpoch 35/200\n116/116 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8462 - val_loss: 0.5417 - val_accuracy: 0.8265\nEpoch 36/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.8478 - val_loss: 0.5298 - val_accuracy: 0.8319\nEpoch 37/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8519 - val_loss: 0.5183 - val_accuracy: 0.8319\nEpoch 38/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.8557 - val_loss: 0.5073 - val_accuracy: 0.8341\nEpoch 39/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.8589 - val_loss: 0.4971 - val_accuracy: 0.8395\nEpoch 40/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8587 - val_loss: 0.4872 - val_accuracy: 0.8395\nEpoch 41/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.8625 - val_loss: 0.4779 - val_accuracy: 0.8438\nEpoch 42/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8654 - val_loss: 0.4689 - val_accuracy: 0.8449\nEpoch 43/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8695 - val_loss: 0.4602 - val_accuracy: 0.8503\nEpoch 44/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8725 - val_loss: 0.4521 - val_accuracy: 0.8525\nEpoch 45/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8755 - val_loss: 0.4442 - val_accuracy: 0.8547\nEpoch 46/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8766 - val_loss: 0.4370 - val_accuracy: 0.8601\nEpoch 47/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8814 - val_loss: 0.4298 - val_accuracy: 0.8612\nEpoch 48/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8831 - val_loss: 0.4232 - val_accuracy: 0.8633\nEpoch 49/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8866 - val_loss: 0.4165 - val_accuracy: 0.8688\nEpoch 50/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8871 - val_loss: 0.4102 - val_accuracy: 0.8688\nEpoch 51/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8912 - val_loss: 0.4042 - val_accuracy: 0.8698\nEpoch 52/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8939 - val_loss: 0.3985 - val_accuracy: 0.8720\nEpoch 53/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8950 - val_loss: 0.3928 - val_accuracy: 0.8731\nEpoch 54/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8956 - val_loss: 0.3875 - val_accuracy: 0.8731\nEpoch 55/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8964 - val_loss: 0.3822 - val_accuracy: 0.8753\nEpoch 56/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8961 - val_loss: 0.3776 - val_accuracy: 0.8753\nEpoch 57/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8980 - val_loss: 0.3727 - val_accuracy: 0.8785\nEpoch 58/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8993 - val_loss: 0.3679 - val_accuracy: 0.8796\nEpoch 59/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8991 - val_loss: 0.3635 - val_accuracy: 0.8818\nEpoch 60/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.9002 - val_loss: 0.3592 - val_accuracy: 0.8829\nEpoch 61/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.9004 - val_loss: 0.3552 - val_accuracy: 0.8839\nEpoch 62/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.9004 - val_loss: 0.3510 - val_accuracy: 0.8872\nEpoch 63/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.9023 - val_loss: 0.3472 - val_accuracy: 0.8883\nEpoch 64/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3056 - accuracy: 0.9040 - val_loss: 0.3435 - val_accuracy: 0.8905\nEpoch 65/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.9048 - val_loss: 0.3399 - val_accuracy: 0.8905\nEpoch 66/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.9067 - val_loss: 0.3364 - val_accuracy: 0.8926\nEpoch 67/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.9075 - val_loss: 0.3331 - val_accuracy: 0.8926\nEpoch 68/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.9091 - val_loss: 0.3298 - val_accuracy: 0.8937\nEpoch 69/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.9094 - val_loss: 0.3264 - val_accuracy: 0.8948\nEpoch 70/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.9094 - val_loss: 0.3233 - val_accuracy: 0.8948\nEpoch 71/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.9107 - val_loss: 0.3205 - val_accuracy: 0.8959\nEpoch 72/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.9126 - val_loss: 0.3176 - val_accuracy: 0.8970\nEpoch 73/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.9145 - val_loss: 0.3148 - val_accuracy: 0.8980\nEpoch 74/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2729 - accuracy: 0.9154 - val_loss: 0.3121 - val_accuracy: 0.9002\nEpoch 75/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2702 - accuracy: 0.9164 - val_loss: 0.3095 - val_accuracy: 0.9013\nEpoch 76/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2675 - accuracy: 0.9170 - val_loss: 0.3070 - val_accuracy: 0.9002\nEpoch 77/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.9173 - val_loss: 0.3044 - val_accuracy: 0.9013\nEpoch 78/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.9175 - val_loss: 0.3018 - val_accuracy: 0.9013\nEpoch 79/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 0.9183 - val_loss: 0.2993 - val_accuracy: 0.9024\nEpoch 80/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.9186 - val_loss: 0.2970 - val_accuracy: 0.9046\nEpoch 81/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.9200 - val_loss: 0.2949 - val_accuracy: 0.9056\nEpoch 82/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.9219 - val_loss: 0.2929 - val_accuracy: 0.9067\nEpoch 83/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.9211 - val_loss: 0.2907 - val_accuracy: 0.9067\nEpoch 84/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.9216 - val_loss: 0.2884 - val_accuracy: 0.9089\nEpoch 85/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.9224 - val_loss: 0.2864 - val_accuracy: 0.9100\nEpoch 86/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.9230 - val_loss: 0.2846 - val_accuracy: 0.9100\nEpoch 87/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2425 - accuracy: 0.9240 - val_loss: 0.2829 - val_accuracy: 0.9111\nEpoch 88/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2406 - accuracy: 0.9243 - val_loss: 0.2809 - val_accuracy: 0.9111\nEpoch 89/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9243 - val_loss: 0.2792 - val_accuracy: 0.9121\nEpoch 90/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2369 - accuracy: 0.9257 - val_loss: 0.2773 - val_accuracy: 0.9121\nEpoch 91/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.9251 - val_loss: 0.2758 - val_accuracy: 0.9121\nEpoch 92/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.9259 - val_loss: 0.2741 - val_accuracy: 0.9121\nEpoch 93/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.9259 - val_loss: 0.2724 - val_accuracy: 0.9121\nEpoch 94/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9270 - val_loss: 0.2709 - val_accuracy: 0.9143\nEpoch 95/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2283 - accuracy: 0.9270 - val_loss: 0.2693 - val_accuracy: 0.9143\nEpoch 96/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2267 - accuracy: 0.9273 - val_loss: 0.2675 - val_accuracy: 0.9154\nEpoch 97/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9289 - val_loss: 0.2661 - val_accuracy: 0.9154\nEpoch 98/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9286 - val_loss: 0.2646 - val_accuracy: 0.9154\nEpoch 99/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9295 - val_loss: 0.2634 - val_accuracy: 0.9154\nEpoch 100/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.9303 - val_loss: 0.2618 - val_accuracy: 0.9165\nEpoch 101/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2192 - accuracy: 0.9305 - val_loss: 0.2605 - val_accuracy: 0.9165\nEpoch 102/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2179 - accuracy: 0.9295 - val_loss: 0.2591 - val_accuracy: 0.9165\nEpoch 103/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.9303 - val_loss: 0.2580 - val_accuracy: 0.9165\nEpoch 104/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9316 - val_loss: 0.2566 - val_accuracy: 0.9165\nEpoch 105/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9319 - val_loss: 0.2553 - val_accuracy: 0.9165\nEpoch 106/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9314 - val_loss: 0.2543 - val_accuracy: 0.9165\nEpoch 107/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9319 - val_loss: 0.2530 - val_accuracy: 0.9165\nEpoch 108/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9322 - val_loss: 0.2518 - val_accuracy: 0.9176\nEpoch 109/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9322 - val_loss: 0.2507 - val_accuracy: 0.9176\nEpoch 110/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9330 - val_loss: 0.2497 - val_accuracy: 0.9176\nEpoch 111/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2066 - accuracy: 0.9327 - val_loss: 0.2485 - val_accuracy: 0.9176\nEpoch 112/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2055 - accuracy: 0.9324 - val_loss: 0.2475 - val_accuracy: 0.9176\nEpoch 113/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2043 - accuracy: 0.9335 - val_loss: 0.2465 - val_accuracy: 0.9176\nEpoch 114/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9346 - val_loss: 0.2457 - val_accuracy: 0.9187\nEpoch 115/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2022 - accuracy: 0.9349 - val_loss: 0.2446 - val_accuracy: 0.9187\nEpoch 116/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2011 - accuracy: 0.9349 - val_loss: 0.2437 - val_accuracy: 0.9187\nEpoch 117/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 0.9354 - val_loss: 0.2426 - val_accuracy: 0.9187\nEpoch 118/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1990 - accuracy: 0.9362 - val_loss: 0.2417 - val_accuracy: 0.9187\nEpoch 119/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1981 - accuracy: 0.9365 - val_loss: 0.2407 - val_accuracy: 0.9187\nEpoch 120/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9357 - val_loss: 0.2400 - val_accuracy: 0.9208\nEpoch 121/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9376 - val_loss: 0.2391 - val_accuracy: 0.9187\nEpoch 122/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9360 - val_loss: 0.2383 - val_accuracy: 0.9197\nEpoch 123/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9362 - val_loss: 0.2373 - val_accuracy: 0.9208\nEpoch 124/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1934 - accuracy: 0.9373 - val_loss: 0.2365 - val_accuracy: 0.9219\nEpoch 125/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9371 - val_loss: 0.2358 - val_accuracy: 0.9219\nEpoch 126/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9371 - val_loss: 0.2351 - val_accuracy: 0.9219\nEpoch 127/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1907 - accuracy: 0.9379 - val_loss: 0.2343 - val_accuracy: 0.9219\nEpoch 128/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9381 - val_loss: 0.2335 - val_accuracy: 0.9219\nEpoch 129/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1890 - accuracy: 0.9384 - val_loss: 0.2327 - val_accuracy: 0.9230\nEpoch 130/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9379 - val_loss: 0.2320 - val_accuracy: 0.9241\nEpoch 131/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9376 - val_loss: 0.2315 - val_accuracy: 0.9241\nEpoch 132/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1865 - accuracy: 0.9381 - val_loss: 0.2307 - val_accuracy: 0.9241\nEpoch 133/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1857 - accuracy: 0.9387 - val_loss: 0.2300 - val_accuracy: 0.9241\nEpoch 134/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1849 - accuracy: 0.9390 - val_loss: 0.2293 - val_accuracy: 0.9241\nEpoch 135/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9387 - val_loss: 0.2286 - val_accuracy: 0.9230\nEpoch 136/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.9398 - val_loss: 0.2279 - val_accuracy: 0.9230\nEpoch 137/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1827 - accuracy: 0.9403 - val_loss: 0.2274 - val_accuracy: 0.9230\nEpoch 138/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9392 - val_loss: 0.2266 - val_accuracy: 0.9230\nEpoch 139/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1812 - accuracy: 0.9403 - val_loss: 0.2260 - val_accuracy: 0.9241\nEpoch 140/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1805 - accuracy: 0.9403 - val_loss: 0.2254 - val_accuracy: 0.9230\nEpoch 141/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1798 - accuracy: 0.9409 - val_loss: 0.2245 - val_accuracy: 0.9241\nEpoch 142/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.9409 - val_loss: 0.2239 - val_accuracy: 0.9241\nEpoch 143/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9406 - val_loss: 0.2234 - val_accuracy: 0.9241\nEpoch 144/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9409 - val_loss: 0.2230 - val_accuracy: 0.9241\nEpoch 145/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9403 - val_loss: 0.2222 - val_accuracy: 0.9219\nEpoch 146/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9411 - val_loss: 0.2218 - val_accuracy: 0.9241\nEpoch 147/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.9409 - val_loss: 0.2214 - val_accuracy: 0.9230\nEpoch 148/200\n116/116 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9414 - val_loss: 0.2206 - val_accuracy: 0.9241\nEpoch 149/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9409 - val_loss: 0.2201 - val_accuracy: 0.9241\nEpoch 150/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1739 - accuracy: 0.9411 - val_loss: 0.2196 - val_accuracy: 0.9241\nEpoch 151/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9411 - val_loss: 0.2193 - val_accuracy: 0.9252\nEpoch 152/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9419 - val_loss: 0.2187 - val_accuracy: 0.9252\nEpoch 153/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1721 - accuracy: 0.9425 - val_loss: 0.2184 - val_accuracy: 0.9252\nEpoch 154/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9436 - val_loss: 0.2179 - val_accuracy: 0.9252\nEpoch 155/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9425 - val_loss: 0.2176 - val_accuracy: 0.9252\nEpoch 156/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9425 - val_loss: 0.2170 - val_accuracy: 0.9252\nEpoch 157/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9433 - val_loss: 0.2165 - val_accuracy: 0.9252\nEpoch 158/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1692 - accuracy: 0.9430 - val_loss: 0.2159 - val_accuracy: 0.9252\nEpoch 159/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9430 - val_loss: 0.2155 - val_accuracy: 0.9252\nEpoch 160/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9438 - val_loss: 0.2150 - val_accuracy: 0.9241\nEpoch 161/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1676 - accuracy: 0.9438 - val_loss: 0.2145 - val_accuracy: 0.9241\nEpoch 162/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9452 - val_loss: 0.2143 - val_accuracy: 0.9241\nEpoch 163/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9447 - val_loss: 0.2139 - val_accuracy: 0.9252\nEpoch 164/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9441 - val_loss: 0.2132 - val_accuracy: 0.9252\nEpoch 165/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1656 - accuracy: 0.9452 - val_loss: 0.2129 - val_accuracy: 0.9241\nEpoch 166/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9447 - val_loss: 0.2124 - val_accuracy: 0.9241\nEpoch 167/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9455 - val_loss: 0.2119 - val_accuracy: 0.9230\nEpoch 168/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1640 - accuracy: 0.9460 - val_loss: 0.2116 - val_accuracy: 0.9230\nEpoch 169/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.9457 - val_loss: 0.2112 - val_accuracy: 0.9241\nEpoch 170/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9463 - val_loss: 0.2108 - val_accuracy: 0.9241\nEpoch 171/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9468 - val_loss: 0.2104 - val_accuracy: 0.9252\nEpoch 172/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9463 - val_loss: 0.2101 - val_accuracy: 0.9252\nEpoch 173/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1616 - accuracy: 0.9466 - val_loss: 0.2097 - val_accuracy: 0.9252\nEpoch 174/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9468 - val_loss: 0.2094 - val_accuracy: 0.9252\nEpoch 175/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.9471 - val_loss: 0.2090 - val_accuracy: 0.9262\nEpoch 176/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1603 - accuracy: 0.9471 - val_loss: 0.2085 - val_accuracy: 0.9252\nEpoch 177/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.9468 - val_loss: 0.2081 - val_accuracy: 0.9262\nEpoch 178/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.9460 - val_loss: 0.2078 - val_accuracy: 0.9262\nEpoch 179/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9476 - val_loss: 0.2075 - val_accuracy: 0.9262\nEpoch 180/200\n116/116 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.9471 - val_loss: 0.2070 - val_accuracy: 0.9252\nEpoch 181/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9482 - val_loss: 0.2068 - val_accuracy: 0.9262\nEpoch 182/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9471 - val_loss: 0.2063 - val_accuracy: 0.9273\nEpoch 183/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9479 - val_loss: 0.2060 - val_accuracy: 0.9273\nEpoch 184/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1568 - accuracy: 0.9471 - val_loss: 0.2056 - val_accuracy: 0.9273\nEpoch 185/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 0.9482 - val_loss: 0.2052 - val_accuracy: 0.9273\nEpoch 186/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1560 - accuracy: 0.9476 - val_loss: 0.2050 - val_accuracy: 0.9262\nEpoch 187/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9485 - val_loss: 0.2046 - val_accuracy: 0.9262\nEpoch 188/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.9487 - val_loss: 0.2042 - val_accuracy: 0.9262\nEpoch 189/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9479 - val_loss: 0.2039 - val_accuracy: 0.9262\nEpoch 190/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9485 - val_loss: 0.2038 - val_accuracy: 0.9262\nEpoch 191/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1540 - accuracy: 0.9482 - val_loss: 0.2035 - val_accuracy: 0.9262\nEpoch 192/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9479 - val_loss: 0.2032 - val_accuracy: 0.9262\nEpoch 193/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9490 - val_loss: 0.2027 - val_accuracy: 0.9273\nEpoch 194/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9493 - val_loss: 0.2022 - val_accuracy: 0.9262\nEpoch 195/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9487 - val_loss: 0.2019 - val_accuracy: 0.9273\nEpoch 196/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9482 - val_loss: 0.2017 - val_accuracy: 0.9273\nEpoch 197/200\n116/116 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9490 - val_loss: 0.2016 - val_accuracy: 0.9273\nEpoch 198/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1514 - accuracy: 0.9487 - val_loss: 0.2011 - val_accuracy: 0.9262\nEpoch 199/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9487 - val_loss: 0.2009 - val_accuracy: 0.9262\nEpoch 200/200\n116/116 [==============================] - 0s 3ms/step - loss: 0.1507 - accuracy: 0.9498 - val_loss: 0.2007 - val_accuracy: 0.9273\n","output_type":"stream"},{"execution_count":257,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7616f5200700>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}